# 【コラム】2015年のAIと、今のAIは何が違うのか？
## —— 「道具」から「相棒」へ進化した技術的理由（完全版）

先日、福岡支店での講演（Vive-with-Gemini）の際、2015年頃からAI開発に携わっていた方から、鋭い質問をいただきました。

> **「今のAIも、結局は過去のデータから相関関係を見ているだけですよね？ 因果関係を理解しているわけではないのに、なぜこれほど『対話』が成立するのですか？」**

この質問は、AIの本質を突いています。
2015年当時のAI（ディープラーニング初期）を知る技術者にとって、AIとは「データを分類する『道具』」でした。しかし、今の私たちが実践している Vive-with-Gemini は、AIを「共に考える『相棒』」として扱います。

なぜ、AIは「道具」から「相棒」へと格上げされたのか？
その背景には、**「計算の物理的な質的変化」**と**「使い方の革命」**がありました。

---

## 1. 2015年の常識：「相関関係の計算機」

2015年頃、AI（CNNやRNN）は「猫の画像」を見て「猫」と答えることはできましたが、「なぜ猫なのか」を説明することはできませんでした。
当時の認識通り、AIの仕組みは**「統計的な相関関係（パターンマッチング）」**であり、それは現在も変わっていません。

AIは言葉の意味を理解しているわけではありません。すべての言葉を**「ベクトル（数百〜数千次元の数字の列）」**に変換し、ベクトル同士の**「向き（コサイン類似度）」**が近いかどうかで、「意味の近さ」を判定しています。
この「ベクトル計算」こそがAIの実体です。

## 2. 2017年の革命と「NVIDIA一強」の理由

転機は2017年、**Transformer（トランスフォーマー）**の登場でした。これがすべてを変えました。

それまでのAI（RNN）は、文章を前から順に計算する「伝言ゲーム」でした。
しかしTransformerは、文章中の**すべての単語ベクトル同士の掛け算（行列演算）**を、**「せーの！」で一気に（並列に）**行う仕組みでした。

ここでハードウェアの運命が決まりました。
* **CPU:** 複雑な処理を順番にこなすのが得意（指揮官）。
* **GPU:** 単純な計算を同時に大量にこなすのが得意（数千人の兵隊）。

Transformerの登場により、AIの計算は**「巨大な行列演算の並列処理」**そのものになりました。
結果として、この計算処理に特化していた**NVIDIAのGPU**が、グラフィックス用途を超えて「AIの頭脳」として必須となり、現在の「NVIDIA一人勝ち」の状態が生まれたのです。

この物理的な計算力の爆発により、AIは以前とは桁違いのデータ量を飲み込めるようになり、**「文脈全体を保持したまま思考する」**能力を手に入れました。

## 3. 量が質を変えた：「創発」という現象

さらに、**Scaling Laws（スケーリング則）**という発見がありました。
「GPUを並べてデータと計算量を増やせば増やすほど、AIは賢くなる」という法則です。

AIにインターネット上のほぼ全てのテキストを学習させた結果、**「創発（Emergence）」**という現象が起きました。
仕組み上は「次に来る言葉を確率で予測しているだけ」なのに、あたかも**「因果関係を理解し、論理的に推論しているかのような振る舞い」**を獲得したのです。

* **Before:** 特定タスク専用のモデルを、職人芸で「作る」時代。
* **After:** すでに博識な巨大モデルに、指示を出して「指揮する」時代。

## 4. 現場での活用技術：RAGとLoRA

この「巨大な汎用脳」を、私たちの現場（Vive-with-Gemini）で「相棒」にするために使われているのが、**RAG**と**LoRA**です。

* **RAG（検索拡張生成）：**
    AIは賢いですが、私たちのプロジェクトのことは知りません。そこで、社内規約や設計書を検索させ、それを「カンニングペーパー」として渡すことで、**「文脈を知っている相棒」**にします。
* **LoRA（ローラ）：**
    巨大なモデル本体（脳）を再学習させるのは数億円かかります。そこで、脳の外側に「薄いフィルター（アダプター）」だけをくっつけて、そこだけを学習させる技術です。これにより、低コストで**「チーム専用の性格」**を持たせることができます。

## 5. そして未来へ：「学習」から「推論」の時代

最後に、これからのトレンドについて触れます。
これまでは、賢いAIを作るための**「学習（Training）」**に大量のGPUが必要とされ、そこにお金が集まっていました。いわば「大学で勉強する期間」です。

しかしこれからは、社会に出たAIが毎日仕事をする**「推論（Inference）」**のフェーズに入ります。
私たちが毎日AIと対話し、コードを書かせ、レビューをさせるたびに、裏側ではGPUが推論の計算を回しています。

Vive-with-Gemini が目指す「常にAIと対話するスタイル」が一般的になればなるほど、**学習よりも推論のために必要なGPUリソースの方が圧倒的に多くなる**と言われています。
「作る競争」から「使い倒す競争」へ。フェーズは確実に変わっています。

---

## 結論：Vive-with-Gemini が「相棒」と呼ぶ理由

2015年のAIは、特定の作業を自動化する優れた「道具」でした。
2025年のAIは、**GPUによる並列計算**と**トランスフォーマー**の力で文脈を保持し、**RAG**で私たちの現場知識を武装した、頼れる**「相棒」**です。

かつての技術を知る方こそ、この「中身は相関関係の行列計算なのに、振る舞いが人間のような相棒になった」という進化の面白さを、ぜひ現場のペアプロを通じて体感していただければと思います。

---
👉 [前の記事：「現場で磨かれるAI活用術：Vive-with-Gemini実践編」に戻る](./ai-agile-vive-with-gemini-extended)