# 1 API整合性のためのSagaパターン

![S1.API整合性のためのSagaパターン](/images/gamehub/S1.API整合性のためのSagaパターン.jpg)

## このページの要点

この資料のテーマは「**複数SaaSにまたがるAPI統合で、整合性（Consistency）をどう設計するか**」であり、その中心に <strong>Sagaパターン（補償トランザクション）</strong>があります。

## まず前提：トランザクションとは何か（初心者向け）

* **単一DB内**のトランザクションは、一般に **ACID**（原子性・一貫性・独立性・耐久性）を満たすよう設計できます。
* 一方で、**複数サービス（SaaS、別DB、外部API）**にまたがると、1つのDBのようには扱えず、「全部成功 or 全部失敗」を**単純には**作れません。

## “グローバルトランザクション”が難しい理由（概念）

* 古典的には **2PC（Two-Phase Commit）** や **XA** のように、複数リソースを1つのトランザクションで束ねる方式があります。
* しかし外部SaaSは「あなたの2PCに参加」してくれません。外部API呼び出し後に、DBの `ROLLBACK` のような巻き戻しができないのが普通です。
* そのため実務では、**分散システムは“失敗が起きる前提”で整合性を設計**し、Sagaのようなパターンで“回復”を作ります。

---

# 2 マルチSaaS統合の課題：データはどこにあるのか？

![S2.マルチSaaS統合の課題：データはどこにあるのか？](/images/gamehub/S2.マルチSaaS統合の課題：データはどこにあるのか？.jpg)

## 図が示していること

顧客データが「1か所に集約されず」、用途別SaaS（例：コマース、サポート、SNS、会員ID）に **分散**している状態を示しています。

## 重要なメッセージ

> 課題は「データを移動させること」ではなく、**リンクが切れても整合性を維持し続けること**
> という発想がポイントです。統合＝一元化ではなく、<strong>分散したまま“正しく連携し続ける設計”</strong>が必要になります。

## 補足：整合性の種類（初心者向け）

* **強整合（Strong Consistency）**：常に最新が見える（ただし分散ではコスト増、停止に弱い）
* **結果整合（Eventual Consistency）**：時間はかかるが最終的には一致する（現実的な落とし所）

マルチSaaS統合は多くが **結果整合を前提**にし、失敗時の回復（再試行・補償・手戻り）を設計していきます。

---

# 3 アーキテクチャ：サーバーレス企業アプリ統合システム

![S3.アーキテクチャソリューション：サーバレスEAI](/images/gamehub/S3.アーキテクチャソリューション：サーバレスEAI.jpg)

## 図が示していること

クライアント → **API Gateway** → **Lambda（ロジック層）** →（外部SaaSコネクタ群）＋（内部DB：Aurora）という、サーバーレス中心のEAI（Enterprise Application Integration）構成です。

## なぜ“ハブ”が必要か

* SaaSごとにAPI仕様、認証、レート制限、障害特性が違う
* クライアントが直接複数SaaSを叩くと、変更・障害の影響範囲が爆発する
  → そこで <strong>Lambda（またはBFF/統合層）</strong>に統合責務を集約し、外部の変化を吸収します。

## 補足：状態（State）の置き方が設計の肝

分散トランザクションの実装では「**進捗状態（どこまで成功したか）**」を保持できる場所が必要です。

* 図では **Aurora** が “State” として描かれており、Sagaの進捗や顧客マスタの正本として重要になります。

---

# 4 同期オーケストレーション（正常系）

![S4.同期オーケストレーション（正常系）](/images/gamehub/S4.同期オーケストレーション（正常系）.jpg)

## 図が示していること

顧客登録/更新の要求に対して、Lambda（CustomerCreate）が

* Aurora（顧客基本台帳）
* コマース
* サポート
  へ同期的に更新し、全部成功（チェック）なら「完全同期」になる流れです。

## 同期のメリット/デメリット

**メリット**

* APIレスポンス時点で「全部揃った」と言いやすい（UXが単純）
* 直後の読み取りが整合しやすい

**デメリット**

* どこか1つ遅い/不安定だと全体が遅くなる
* タイムアウトやリトライが増える
* 下流SaaSのレート制限に直撃しやすい

> 正常系だけ見ると美しいが、分散では「失敗時」を主役に設計する必要があります。

---

# 5 「分散トランザクション」の壁（失敗時）

![S5.分散トランザクションの壁](/images/gamehub/S5.分散トランザクションの壁.jpg)

## 図が示していること

サポートシステム連携が **500/Timeout** で失敗した場合に、

* Auroraや他SaaSは更新済み
* サポートだけ未更新
  となり **データ不整合**が発生する様子です。

## ここが“壁”になる理由（一般論）

単一DBなら `BEGIN … ROLLBACK` で戻せますが、外部APIは通常：

* 「このAPI呼び出しを取り消して」と言う標準手段がない
* 取り消しAPIがあっても“同じ意味での巻き戻し”ではない（副作用が残る）

つまり分散では「ロールバック」よりも <strong>回復（recovery）</strong>が主戦場になります。

## 実務で必須になる設計要素

* **冪等性（Idempotency）**：同じ要求を複数回送っても結果が壊れない
* **リトライ戦略**：指数バックオフ、最大回数、タイムアウト分離
* **失敗の記録**：どこまで成功したか（Saga状態）を保持し、再実行できる

---

# 6 Sagaパターン：補償トランザクション

![S6.Sagaパターンの導入：補償トランザクション](/images/gamehub/S6.Sagaパターンの導入：補償トランザクション.jpg)

## 図が示していること

処理を Step1→Step2→Step3 と進め、途中で失敗したら **Undo（補償）**で前段を取り消して「最終的に整合する状態へ戻す」流れです。

## Sagaの考え方（初心者向け）

* Saga = **複数のローカルトランザクションの連鎖**
* 各ステップは「ローカルにはコミット」して進む
* 失敗したら、過去ステップを **補償アクション**で取り消す

ここで重要なのは：

* DBのROLLBACKではなく、**業務的な取り消し操作**で戻す
  例：ユーザー作成を取り消すなら「DELETEユーザー」「無効化フラグ」など。

## オーケストレーション vs コレオグラフィ

* **オーケストレーション**：中心（Lambda/Step Functions等）が順序と分岐を制御
* **コレオグラフィ**：イベント駆動で各サービスが自律的に反応
  本資料は “オーケストレーション寄り” の説明です。

---

# 7 実装詳細：会員登録のロールバックロジック

![S7.実装詳細：会員登録のロールバックロジック](/images/gamehub/S7.実装詳細：会員登録のロールバックロジック.jpg)

## 図の読み取り

実装フロー例：

1. PrimaryDB に会員レコード追加
2. サポートへユーザー作成
3. コマースへユーザー作成
4. コマースがエラー
5. **Catch & Compensate（Saga）**：サポートで作ったユーザーを削除、PrimaryDBもロールバック（または補償）

## 実装の勘所（実務）

* DBはトランザクションで戻せても、外部SaaSは戻せないため、**外部側に補償API（削除/無効化）** が必要
* 補償は「完全に元通り」にできない場合がある

  * 監査ログが残る
  * 通知が飛んだ等の副作用
    → だからこそ、補償を含めた業務要件の合意が重要

## 最低限のチェックリスト

* ① 各ステップに **idempotency key** を持たせる（重複作成防止）
* ② 補償も冪等（“既に消えている”を成功扱い）
* ③ 失敗時に「どこまで成功したか」を必ず記録（後で再実行/手動復旧）

---

# 8 複雑な整合性要件：会員名寄せ（Na-yose）

![S8.複雑な整合性要件：会員名寄せ](/images/gamehub/S8.複雑な整合性要件：会員名寄せ.jpg)

## 図が示していること

重複した会員ID（User A / User B）を統合して Target User に寄せる“名寄せ”のSaga例です。ステップとして Aurora更新→コマース更新→サポート更新が描かれています。

## なぜ難しいか（一般論）

名寄せは「作成」より難度が上がります。

* データの統合・移送・参照切替など、**不可逆に近い操作**が増える
* 途中失敗時に“どこに戻すか”が複雑（図でもリスク注意が強調）

## 実務上の現実解

* **“完全自動ロールバック”に固執しない**

  * ある地点まで自動補償
  * 以降は「運用介入（手動復旧）」を前提にする設計も合理的
* そのために必要なのが

  * 監査ログ
  * 差分レポート
  * リカバリ手順書（Runbook）
  * 再実行可能なジョブ化

---

# 9 非同期デカップリング（Queue Pattern）

![S9.非同期デカップリング（QueuePattern）](/images/gamehub/S9.非同期デカップリング（QueuePattern）.jpg)

## 図の読み取り

クライアントが `/api/async` にPOSTすると **202 Accepted** を即時返し、裏側で **SQS → Lambda(Worker)** が処理してSaaSを更新します。

## 何が嬉しいか

* **即時応答**：ユーザー待ち時間を最小化
* **流量制御**：Lambda同時実行数で下流SaaSを保護（レート制限回避）
* **耐障害性**：失敗したメッセージをDLQに逃がして後で再処理

## “トランザクション”的に見ると

* 同期一括より **結果整合（Eventual Consistency）**に寄る
* その代わり、処理状態を「ジョブ」として追跡しやすくなる

  * ステータス（PENDING/RUNNING/SUCCEEDED/FAILED）
  * 再試行回数
  * 最終エラー

---

# 10 ゲートキーパー：エッジでのバリデーション

![S10.ゲートキーパー：エッジでのバリデーション](/images/gamehub/S10.ゲートキーパー：エッジでのバリデーション.jpg)

## 図の読み取り

`cust_no（顧客番号）` 欠落のリクエストを API Gateway で弾き **400 Bad Request** にし、Lambdaを起動しない（No Invoke）という例です。YAMLで `validateRequestParameters: true` のような仕掛けが示されています。

## なぜ“トランザクション整合性”に効くのか

Sagaは「副作用の連鎖」です。入力が不正だと：

* 途中まで外部システムを更新してから失敗
* 補償が走っても完全に戻せない
  という事故が起きます。

つまり **入口で不正を遮断することは、整合性設計の一部**です。

---

# 11 セキュリティと抽象化（API Gateway Facade）

![S11.セキュリティと抽象化](/images/gamehub/S11.セキュリティと抽象化.jpg)

## 図の読み取り

フロントは API Gateway（Facade）だけを見て、背後の複数システム（コマース/サポート/会員/DB）を隠蔽しています。さらに `type: mock` の記載があり、開発・保守時にバックエンド無しで固定レスポンスを返す“モック統合”を示唆します。

## 分散整合性の観点での価値

* セキュリティ境界が明確（認証/認可/スロットリング/監査）
* 仕様変更をFacadeで吸収し、下流の“契約”を守りやすい
* モックにより、Sagaの分岐やエラーハンドリングを **安全にテスト**しやすい

---

# 12 安全なデプロイ：Canaryリリース

![S12.安全なデプロイメント：Canaryリリース](/images/gamehub/S12.安全なデプロイメント：Canaryリリース.jpg)

## 図の読み取り

トラフィックの大半（例：95%）を v1 に流しつつ、少量（例：5%）を v2 に流し、CloudWatch監視しながら段階移行するカナリアリリースです。

## Sagaロジックでカナリアが重要な理由

Sagaは「失敗時の補償」を含むため、バグがあると：

* 外部SaaSに誤更新
* 補償が誤動作してさらに破壊
  という“二次災害”になりがちです。

カナリア＋監視で「被害半径」を小さくし、問題があれば即座に戻せます。

---

# 13 オブザーバビリティ：Sagaの追跡

![S13.オブザーバビリティ：Sagaの追跡](/images/gamehub/S13.オブザーバビリティ：Sagaの追跡.jpg)

## 図の読み取り

構造化ログ（JSON）に `level`, `function_request_id`, `function_name`, `message`, `error_code` などを含め、CloudWatch Alarm と Metric Filter（例：`$.level = "ERROR"`）で異常検知する例です。

## 分散トランザクションで“追跡”が必須な理由

* 失敗は避けられない
* 重要なのは「どの取引が」「どこで」「どの状態で」止まったか
  つまり **トランザクションID（相関ID）**が必要です。

### 実務の推奨

* 取引ID（correlation id）を API→Lambda→SQS→下流呼び出しまで必ず伝播
* ログだけでなく、可能ならトレース（OpenTelemetry等）で可視化
* 失敗はDLQへ、DLQには“再実行ボタン”相当の運用手順を用意

---

# 14 導入効果のまとめ

![S14.導入効果のまとめ](/images/gamehub/S14.導入効果のまとめ.jpg)

## 図の読み取り（4象限）

* 堅牢な整合性（Consistency）：Saga/Queueで不整合を抑制
* スケーラビリティ（Scalability）：サーバーレスで自動スケール
* コスト効率（Cost Efficiency）：無駄な待機や無駄invoke削減
* アジリティ（Agility）：疎結合で改善・テストが容易

## 補足：この4象限はトレードオフ管理でもある

* 強整合を求めすぎるとスケール/コスト/可用性が悪化
* 結果整合を採用するなら、観測・再実行・補償が必須
  → “整合性は偶然ではなく設計”の要旨につながります。

---

# 15 結論（設計された一貫性）

![S15.結論](/images/gamehub/S15.結論.jpg)

## 図の読み取り

Client → API Gateway → Lambda を中心に、SQSやAurora、複数SaaSへ連携する全体像のまとめです。下部に「分散世界で一貫性は偶然ではなく、エンジニアリングで設計される」との趣旨が示されています。

## まとめ（読者向けの腹落ちポイント）

1. 外部SaaSを含む統合では、単純な“ロールバック”は成立しにくい
2. だから Saga（補償）／Queue（非同期）／Validation（入口防御）／Observability（追跡）を組み合わせる
3. 一貫性はDB機能だけの話ではなく、**運用・監視・再処理まで含む総合設計**で実現する

---

## 追加提案（参考書化の完成度を上げる）

今後の活動で以下の３点の深堀も考えています。

* **TX-A01：分散トランザクション総論**（2PC / XA / CAP / 結果整合）
* **TX-A02：Saga設計チェックリスト**（冪等性、補償、タイムアウト、再試行、DLQ、監査）
* **TX-A03：AWS実装パターン**（Lambda + SQS + Dynamo/AuroraでのSaga状態管理、Step Functions比較）
