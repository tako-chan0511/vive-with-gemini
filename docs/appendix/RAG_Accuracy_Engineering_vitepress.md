## 1. ガイド全体の狙い：RAG精度は「データ工学」で決まる
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- RAG（検索＋生成）の精度は **モデルの賢さより、投入する知識（データ）の質**に強く依存します。
- 図は「未整備データ → 精製ライン → 高品質ナレッジ」へ変換する工程（Data Refinery）を表しています。

### 詳細解説（用語）
- **RAG（Retrieval Augmented Generation）**：質問に関連する文書断片（コンテキスト）を検索で集め、その根拠を使ってLLMが回答する方式。
- **ナレッジベース（Knowledge Base）**：PDF/Word/Notion/Confluence/社内Wiki等の一次情報を、検索できる形（チャンク＋メタデータ＋埋め込み）にした集合。
- **埋め込み（Embedding）**：文章をベクトル化して「意味の近さ」で検索できるようにする表現。

### Tips（実務）
- まず「代表質問セット（5〜20問）」を作り、以後の改善は **同じ質問で比較**します（改善が“見える化”されます）。
- 目的を1つ決める：例）「FAQの正答率を上げる」「根拠引用を必須にする」「古い手順を出さない」など。目的が混ざるとチューニングが迷走します。

---

## 2. なぜRAGは間違えるのか：原因の8割はデータ品質
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- 「Garbage In → Garbage Out」：**低品質なコンテキスト**を渡すと、どれだけ強いモデルでも誤答しやすい。
- 典型的な失敗：ノイズ混入（関係ない情報）、文脈欠落（チャンク分割ミス）、古い情報（版管理不備）。

### 詳細解説（用語）
- **コンテキスト（根拠）**：検索で取得した文書断片。RAGではここが“答えの材料”。
- **ハルシネーション**：根拠がないのにそれっぽく作り話をすること。RAGは根拠を与えるが、根拠が弱い/不足だと起きる。
- **ドリフト（漂う回答）**：同じ質問でも日によって回答が揺れる状態。検索結果やプロンプトが不安定なときに発生しがち。

### Tips（実務）
- 誤答が出たら、最初に確認する順番はこれが最短です：  
  1) **検索結果（TopK）に正解根拠が入っているか**  
  2) その根拠が **LLMに渡っているか（プロンプト変数）**  
  3) LLMが **根拠を無視していないか（プロンプト指示）**
- 「古い情報を出す」問題は、検索ではなく **データ側（重複/版管理）**が原因のことが多いです。

---

## 3. 高精度RAGを実現するエンジニアリング・パイプライン（全体像）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- 高精度RAGは「製造ライン」：  
  **収集 → 前処理 → チャンク化 → 検索 → 生成 → 評価** の各工程を最適化します。
- どこか1箇所でも弱いと全体精度が落ちます（“ボトルネック理論”）。

### 詳細解説（用語）
- **前処理（Pre-processing）**：ノイズ除去、表現統一、構造化、重複排除など。
- **チャンク（Chunk）**：検索単位に分割した文書断片。
- **TopK**：検索で取得する候補数。Recall↑の代わりにノイズとコスト↑。
- **リランク（Rerank）**：一次検索で拾った候補を、精度の高いモデルで並べ替える工程。

### Tips（実務）
- まずは「最低限の合格ライン」を作るのがコツです：  
  - ノイズ除去（ヘッダ/フッタ/広告）  
  - セマンティックチャンク（章/見出し単位）  
  - ハイブリッド検索（ベクトル＋キーワード）  
  - 根拠限定プロンプト（不明は“不明”）  
  - 評価セットで毎回スコア測定  
  ここまでで“改善できる土台”ができます。

---

## 4. ステップ1：データクレンジング（ノイズ除去）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- ナレッジには「デジタルな埃」が混ざりやすい（ページ番号、ヘッダ/フッタ、メニュー、コピーライト等）。
- ノイズは検索を汚し、誤った根拠を拾う確率を上げます。

### 詳細解説（用語）
- **構造ノイズ**：ヘッダ/フッタ、ページ番号、パンくず、サイドバー、HTML装飾タグなど。
- **表記ゆれ**：全角/半角、用語の揺れ（例：GPU／グラフィックボード／アクセラレータ）。
- **版管理**：同じ内容の複数版が混在すると、検索が“どれを出すか”揺れて精度が落ちます。

### Tips（実務）
- クレンジングは「ルール化」が効きます。例：  
  - `^\s*Page\s*\d+\s*$` のようなページ番号行は削除  
  - すべてのヘッダ行に共通する接頭辞（会社名など）は削除  
  - 同一文書の最新版だけ残し、旧版は別カテゴリに隔離（検索対象外）
- “削除しすぎ”が怖い場合は、いきなり破壊せず **原本は保存＋加工物を別に持つ**のが安全です。

---

## 5. ステップ2：非構造データを「構造化」して機械可読にする
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- PDF/画像/表/HTMLは、そのままだと検索の“意味”が壊れがち。
- 人が理解しやすい形 → **LLMが理解しやすい形（Markdown/JSON）** へ整形します。

### 詳細解説（用語）
- **OCR**：画像文字をテキスト化する処理。スキャンPDFや図表はOCRしないと検索に乗りません。
- **キャプション**：図・表の意味を短文で補う説明。図だけだと“何を示すか”が検索で伝わりません。
- **表データの構造保持**：行/列/見出しの関係が崩れると誤解釈しやすい（例：単位や条件列が外れる）。

### Tips（実務）
- 表（Excel/CSV）は“ただの文章”にしない：  
  - Markdownテーブル化（小規模）  
  - JSON化（機械処理しやすい）  
  - 重要列（単位/期間/条件）は必ず同じチャンクに入るようにする
- Webは「本文抽出」が肝：ナビゲーションや関連記事リンクを残すとノイズが急増します。

---

## 6. ステップ3：チャンク設計（固定長 vs セマンティック）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- チャンクの切り方はRAGの**最重要**。ここで文脈が切れると、検索も生成も崩れます。
- 推奨は「セマンティック（意味）単位」で切る（章、見出し、段落、手順ブロック）。

### 詳細解説（用語）
- **固定長チャンク**：Nトークンごとに機械的に分割。実装は簡単だが文脈が切れやすい。
- **セマンティックチャンク**：段落や見出し単位で分割。意味のまとまりを維持しやすい。
- **オーバーラップ**：隣接チャンクを少し重ねる。境界情報の欠落を防ぐ。

### Tips（実務）
- チャンクを設計するときのチェック：  
  - そのチャンクだけ読んで **主語・対象・条件が分かるか**  
  - 手順（Step1→2→3）が **途中で切れていないか**  
  - “これ/それ/前述”など参照語が多い場合、前段落を含める
- 目安：FAQ系は短め（200〜500 tokens）、設計書/手順書は長め（500〜1200 tokens）＋オーバーラップが安定しやすいです。

---

## 7. 応用チャンク：Parent-Child と Contextual Retrieval
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- **Parent-Child**：検索は小さく（child）、LLMには広く（parent）渡す設計で「当たりやすさ」と「理解しやすさ」を両立。
- **Contextual Retrieval**：チャンク単体で意味が通るように、文書コンテキスト（出典/前提）を付与してベクトル化。

### 詳細解説（用語）
- **Parent（親）チャンク**：章や節など、広めのまとまり（LLMに渡す）。
- **Child（子）チャンク**：検索用に細かく切った断片（インデックスに登録）。
- **コンテキスト付与**：例）「売上が3%増」→「2024年度 会社A 決算資料において売上が3%増」。

### Tips（実務）
- Parent-Childが効くケース：  
  - “一文はヒットするが、周辺条件が必要”な仕様書/手順書  
  - 箇条書きが多く、単体だと意味が薄い文書
- Contextual Retrievalの付与項目テンプレ（例）：  
  - 文書名 / 節見出し / 対象システム / 年月 / 範囲（プロダクション/検証）  
  これをチャンク先頭に短く入れるだけで、検索精度が上がることが多いです。

---

## 8. ステップ4：メタデータ（タグ付け）で検索を“賢く”する
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- メタデータは「検索のフィルタ＆優先順位」の材料。
- “同じような文書が多い”現場ほど、メタデータが効きます。

### 詳細解説（用語）
- **メタデータ**：文書の属性（カテゴリ、日付、機密区分、プロダクト、著者、部署、バージョンなど）。
- **フィルタリング**：例）「2024年以降」「内部限定」「マニュアルのみ」などで候補を絞る。
- **検索スコープ**：部署別/プロジェクト別に“出して良い知識”を制御する発想。

### Tips（実務）
- “古い情報を出さない”ための最小メタデータ：  
  - `version`（または `published_at`）  
  - `status`（draft/final/deprecated）  
  - `product`（対象システム）  
  これだけでも事故が減ります。
- 機密区分は最優先で：`public/internal/confidential` を持たせ、回答時に必ずチェックする設計が安全です。

---

## 9. ステップ5：ハイブリッド検索（ベクトル＋キーワード）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- ベクトル検索は「意味」には強いが、型番/ID/固有名詞に弱いことがある。
- キーワード検索（BM25等）はその逆。両者を合わせると取りこぼしが減ります。

### 詳細解説（用語）
- **ベクトル検索**：意味が近い文章を探す。言い換えに強い。
- **キーワード検索（BM25）**：語の一致度で探す。固有名詞・型番に強い。
- **スコア融合**：両検索のランキングを統合し、最終候補を作る。

### Tips（実務）
- “現場あるある”の質問に強くなります：  
  - 「0x8004 が出る」→ キーワードが強い  
  - 「PCが動かない」→ 意味検索が強い  
  - 「SQSの可視性タイムアウトって？」→ 両方が効く
- まずはHybrid ONにして、TopKを少し下げる（ノイズ抑制）→ その後リランクで整える、が安定しやすいです。

---

## 10. 精度の最後の一押し：Reranking（Cross-Encoder）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- 一次検索は速いが粗い（上位にノイズが混ざる）。
- Cross-Encoderで「質問×候補」を精密に照合し、上位の純度を上げます。

### 詳細解説（用語）
- **Cross-Encoder**：質問と候補文書を“同時に”入力して関連度を判定するモデル。精度が高いが計算コストも高い。
- **二段階検索**：  
  1) 高速検索で Top50 など候補収集  
  2) リランクで Top5〜10 を厳選 → LLM入力へ

### Tips（実務）
- リランクは「TopKを増やしてもノイズが増える」問題の解決策になります。  
  - 例：TopK=20（Recall確保）→ リランクでTop5へ（Precision確保）
- もしコストが重い場合は、リランク対象を Top30→Top20 に下げる、または短いチャンク（child）でリランクし、LLMには親を渡す構成が効きます。

---

## 11. 高度な検索：HyDE と GraphRAG（いつ使うべきか）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- **HyDE**：検索語が合わないときに、LLMで“仮の回答文”を作り、それを検索クエリとして使う。
- **GraphRAG**：文書群から知識グラフを作り、関係性を辿って全体像を答えやすくする。

### 詳細解説（用語）
- **HyDE（Hypothetical Document Embeddings）**：質問→仮回答（または仮記事）→その埋め込みで検索。語彙ギャップを埋める。
- **GraphRAG**：エンティティ（人/組織/機能/障害）と関係（依存/原因/影響）を抽出し、グラフ探索＋要約を行う設計。

### Tips（実務）
- HyDEが効く例：  
  - ユーザーが曖昧な言い方をする（現場用語/俗称）  
  - “本当は仕様名があるが、利用者は知らない”系
- GraphRAGが効く例：  
  - 「この半年で障害原因の傾向は？」  
  - 「A機能とB機能の依存関係は？」  
  単一チャンク検索では答えにくい“横断的質問”に強いです。

---

## 12. ステップ6：RAGプロンプト（根拠制約・引用・不明回答）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- RAGは「根拠を渡すだけ」では不十分。  
  **根拠だけで答える**、**根拠がなければ“不明”**、**引用を返す** をプロンプトで明確化します。

### 詳細解説（用語）
- **根拠制約**：コンテキスト外の推測を禁じる指示。
- **引用（Citation）**：どの文書（チャンク）を根拠にしたかを示す。運用での信頼性が上がる。
- **温度（Temperature）**：創造性（揺れ）を増やすパラメータ。RAGは基本低めが安定。

### Tips（実務）
- 使い回せる“RAG用System/Instruction”例（要旨）：
  - 「与えられた context のみを根拠に回答せよ」
  - 「不足なら“不明”と述べ、追加で必要な情報を質問せよ」
  - 「回答末尾に根拠チャンクID/タイトルを列挙せよ」
- “不明と言わせる”のは品質向上です。誤答より100倍安全で、ユーザー体験も長期的に良くなります。

---

## 13. 評価と改善ループ：RAGは“測って直す”が正解
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- 精度改善は一度で終わりません。  
  **評価 → 原因分解 → 修正 → 再評価** のループが必要です。

### 詳細解説（用語）
- **Faithfulness（忠実性）**：根拠に基づいているか（幻覚がないか）。
- **Context Precision**：取得したコンテキストが“本当に答えに必要”だった割合。
- **Answer Relevance**：回答が質問の意図に合っているか。
- **RAGAS/RAGChecker**：RAG評価の枠組み（メトリクス算出、比較、回帰検知）。

### Tips（実務）
- 改善の当たりを付けるコツ：  
  - Context Precision が低い → 検索/リランク/メタデータ/TopK を疑う  
  - Faithfulness が低い → プロンプト（根拠制約）/温度/引用 を疑う  
  - Answer Relevance が低い → チャンク（文脈不足）/クエリ生成（HyDE等）を疑う
- “回帰”が最も怖いので、評価はCIのように定期実行（週次でもOK）すると安定します。

---

## 14. 実装メモ：Difyでの設定例（同様の製品にも応用可）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- 実装では「チャンク設定」「検索方式」「リランク」「引用」を押さえると、初速が出ます。
- 製品がDify以外でも、概念はほぼ共通です。

### 詳細解説（用語）
- **チャンクモード**：セマンティック/親子分割/区切り文字など。
- **ハイブリッド検索**：意味検索とキーワード検索の併用。
- **リランクモデル**：Cross-Encoder等。精度↑、コスト↑。

### Tips（実務）
- まず“安全運転”の初期値（例）：  
  - セマンティックチャンク＋オーバーラップ少し  
  - Hybrid ON  
  - TopK=8〜12 → リランクでTop5  
  - Temperature 低め（0〜0.3目安）  
  - 引用ON＋根拠制約プロンプト
- チューニングは1回に1つだけ変える（原因が見えなくなるのを防止）。

---

## 15. まとめ：高精度RAGチェックリスト（最後の確認）
![Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド](/images/Dify/Ra1.RAGの制度を最大化する：高品質ナレッジベース構築ガイド.jpg)

### 図の要旨
- 最後はチェックリスト化して、運用に乗せます（属人化を防ぐ）。
- 「良いデータ → 良いAI」：品質は工程で作り込みます。

### 詳細解説（用語）
- **Recall（再現率）**：正解根拠を拾えるか。TopKや検索方式で影響。
- **Precision（適合率）**：上位候補がどれだけ“正解に近いか”。リランクで影響。
- **回帰**：改善のつもりが悪化すること。評価の継続が必要。

### Tips（実務）
- 運用チェック（最小セット）：
  - [ ] 版管理（最新版のみが検索対象）  
  - [ ] ノイズ除去（ヘッダ/フッタ/広告）  
  - [ ] セマンティックチャンク（文脈が切れていない）  
  - [ ] メタデータ（カテゴリ/日付/機密）  
  - [ ] Hybrid＋Rerank（ノイズを弾く）  
  - [ ] 根拠制約＋引用＋不明回答  
  - [ ] 評価セットで定期測定（回帰検知）
- “最初から完璧”を狙わず、**評価で見える化→一手ずつ改善**が最短距離です。
