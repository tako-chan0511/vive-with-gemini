# 1. Dify（ディファイ）で「LLMアプリを作って公開する」全体像

![Di1.Difyで始める！LLMアプリ開発と公開への最短ルート](/images/Dify/Di1.Difyで始める！LLMアプリ開発と公開への最短ルート.jpg)

### 図の要旨
- これまでのLLMアプリ開発は、**LLM API / ベクタDB / プロンプト / UI / 認証 / ログ**などを組み合わせる“寄せ集め”になりがち。
- Difyは、その寄せ集めを **ひとつのワークスペース（Studio）** にまとめて「作る→試す→公開する」までを短距離にする、というメッセージ。

### 詳細解説（用語）
- **LLMアプリ**：Chat UIやAPIの背後で、LLMへのプロンプト投入・ツール呼び出し・RAG検索などを制御するアプリ。
- **RAG（Retrieval Augmented Generation）**：質問に対し、外部知識（文書）から関連部分を検索して“根拠”としてLLMに渡し、回答精度を上げる方式。

### Tips（実務）
- Difyを使う価値は「モデルを呼ぶ」ではなく、**アプリの周辺（知識・運用・公開・共有）を含めて一気通貫にする**点。
- “まずMVPを1日で出す”なら、**Dify Cloud**で着手が最短。

---

# 2. Difyとは何か

![Di2.Difyとは？：AI開発の「面倒」を解消する統合プラットフォーム](/images/Dify/Di2.Difyとは？：AI開発の「面倒」を解消する統合プラットフォーム.jpg)

### 図の要旨
- Difyは「LLMアプリ開発のプラットフォーム」。アプリ作成に必要な部品（Model / Prompt / Knowledge / Tools / Publish / Logs）を提供する。

### 詳細解説（用語）
- **Model Provider**：OpenAI等の“LLMを提供する先”。Difyは複数プロバイダを切り替え可能。
- **Knowledge（知識）**：RAG用の文書集合。取り込んで分割（chunk）し、ベクトル化（embedding）して検索できる状態にする。
- **Studio**：アプリ設計（プロンプト、RAG、ツール、フロー）を行うUI。
- **Publish**：Webアプリとして公開／APIとして公開／埋め込みなど。
- **Logs/Tracing**：ユーザーの入力、RAGで拾った根拠、LLMへの最終プロンプト、ツール呼び出しなどの記録。

### Tips（実務）
- LangChain経験者の落とし穴：Difyは“ライブラリ”ではなく**実行環境（プラットフォーム）**。  
  → 「コードで全部組む」より「**構成を管理する**」発想に切り替えると早い。

---

# 3. Step 1：環境構築（Cloud / Self-hosted）

![Di3.Step1：環境構築―クラウドかセルフホストか](/images/Dify/Di3.Step1：環境構築―クラウドかセルフホストか.jpg)

### 図の要旨
- **Dify Cloud**：すぐ使える。MVP向き。
- **Self-hosted（Docker）**：社内閉域、データ統制、コスト制御、カスタマイズ向き。

### 詳細解説（用語）
- **Self-hosted**：自分のサーバ（オンプレ/クラウド）でDifyを動かす形。一般にDocker Composeで起動する。
- **閉域/データ統制**：入力データ（会話ログ・社内文書）が外部に出ないことが要件の場合が多い。

### Tips（実務：最短起動の目安）
```bash
# 例：Self-hosted（公式手順に沿って）clone → compose up
git clone <dify-repo>
cd dify/docker
docker compose up -d
````

* まずはCloudでMVP → 要件が固まったらSelf-hostedへ移行、が現実的。

---

# 4. Step 2：モデル設定（Model Provider）

![Di4.Step2：モデルプロバイダーの設定―AIの「脳」を選ぶ](/images/Dify/Di4.Step2：モデルプロバイダーの設定―AIの「脳」を選ぶ.jpg)

### 図の要旨

* Difyで最初に行うのが **モデルプロバイダの追加**（APIキー設定）。
* モデルの切替ができる＝運用中に**コスト/品質/速度**を変えられる。

### 詳細解説（用語）

* **API Key**：プロバイダの課金・認証に使う鍵。Difyに登録する際は権限・管理ルールが重要。
* **Model**：同じプロバイダでも複数モデル（高性能/低コスト等）がある。

### Tips（実務）

* “どのモデルを選ぶか”より先に、**ログ／評価（p14）** の仕組みを前提に選ぶのが安全。
  → 後からモデルを変えた時に、品質差分が追える。

---

# 5. Step 3：アプリ種類（Chatflow / Workflow）

![Di5.Step3：アプリタイプの選択―ChatflowとWorkflow](/images/Dify/Di5.Step3：アプリタイプの選択―ChatflowとWorkflow.jpg)

### 図の要旨

* **Chatflow**：チャット中心（会話の流れとRAG・ツールを繋ぐ）
* **Workflow**：業務フロー中心（分岐・条件・複数ステップ処理に強い）

### 詳細解説（用語）

* **会話メモリ**：直前までの会話をコンテキストとして保持し、回答に反映する。
* **ノード（Node）**：Workflow/Chatflow内の処理単位（LLM呼び出し、知識検索、HTTPリクエスト等）。

### Tips（実務：選び方）

* **社内FAQ / ナレッジ検索**：まずはChatflowが速い（RAG中心）。
* **申請・受付・チケット作成**など“手順がある”業務：Workflowが向く（条件分岐・検証・外部API連携）。

---

# 6. Step 4（RAG 1/2）：ナレッジ作成

![Di6.Step4：RAG構築（１）―ナレッジベースの作成](/images/Dify/Di6.Step4：RAG構築（１）―ナレッジベースの作成.jpg)

### 図の要旨

* 文書（PDF/MD/HTML等）を取り込み、RAGで使える知識にする。

### 詳細解説（用語）

* **Chunk（チャンク）**：文書を検索可能にするための分割単位。大きすぎるとノイズが増え、小さすぎると文脈が切れる。
* **Embedding（埋め込み）**：文章をベクトル（数値配列）に変換すること。意味が近い文章ほどベクトル距離が近い。
* **ベクタ検索**：質問をEmbedding→近いチャンクをTopK件取得、という流れ。

### Tips（実務）

* RAG品質の8割は「**元文書の整形**」で決まる。

  * 例：FAQはQ/Aを見出し構造にする、章立てを揃える、表はテキスト化できる形にする。
* まずは **小さな知識ベース（10〜30ページ）** で精度の癖を掴む。

---

# 7. Step 4（RAG 2/2）：インデックス／検索設定

![Di7.Step4：RAG構築（２）―分割とインデックス設定](/images/Dify/Di7.Step4：RAG構築（２）―分割とインデックス設定.jpg)

### 図の要旨

* チャンク設定と、検索パラメータ（TopK / Score Threshold）を調整して、根拠の“混ざり”を制御する。

### 詳細解説（用語）

* **TopK**：検索で返すチャンク数。多すぎるとノイズ、少なすぎると根拠不足。
* **Score Threshold**：一定スコア未満のチャンクを捨てる閾値。ハルシネーション抑制に効くことがある。
* **High Quality / Economy**：Embeddingやインデックスの精度・コストに関わるプリセット（名称は環境により異なる）。

### Tips（実務：調整の型）

1. “根拠が出ない” → TopK↑ / チャンクサイズ↑ / 閾値↓
2. “関係ない根拠が混ざる” → TopK↓ / 閾値↑ / 文書を分類してKB分割
3. “似た質問で揺れる” → FAQ形式に整形、同義語を追記、見出しを増やす

---

# 8. Step 5：Studioでオーケストレーション

![Di8.Step5：Studioでの構築―オーケストレーション](/images/Dify/Di8.Step5：Studioでの構築―オーケストレーション.jpg)

### 図の要旨

* Studioで「入力→知識検索→LLM→出力」の流れを組み、プロンプトに知識を差し込む。

### 詳細解説（用語）

* **オーケストレーション**：複数部品（LLM/RAG/ツール）を順序立てて動かすこと。
* **System Prompt**：アプリ全体の振る舞いを決める最上位指示（禁止事項、文体、根拠提示など）。

### Tips（実務）

* まずはSystem Promptに「**根拠がない場合は“不明”と言う**」「**引用（出典）を付ける**」を入れると事故が減る。
* “回答形式”を固定するなら、JSONスキーマや箇条書きテンプレを明示する。

---

# 9. 実践Tips：プロンプトにRAGコンテキストを正しく接続

![Di9.実践Tips：プロンプトとコンテキストの連携](/images/Dify/Di9.実践Tips：プロンプトとコンテキストの連携.jpg)

### 図の要旨

* プロンプト内で <code v-pre>{{context}}</code> のようなプレースホルダを使い、RAGで取得した根拠を挿入するのが基本。

### 詳細解説（用語）

* **コンテキスト注入（Context Injection）**：検索結果（チャンク）をプロンプトに合流させること。
* **ハルシネーション**：根拠がないのに“それっぽく”断言する現象。

### Tips（実務：テンプレ例）

```text
あなたは社内ナレッジに基づく回答者です。
以下の「参考情報」に書かれている範囲だけで回答してください。
参考情報にない場合は「不明」と答えてください。

[参考情報]
{{context}}

[質問]
{{query}}
```

* <code v-pre>{{context}}</code> が空の時に暴走しやすいので、「空なら不明」条件を明示する。

*  **<code v-pre>{{context}}</code>がLLM側で有効にならない場合は、SYSTEMの内容に直接「コンテキスト」を[x]メニューより選んで差し込むとよい場合がある。**

---

# 10. Step 6：Agentとツール連携

![Di10.Step6：エージェントとツールーAIに行動させる](/images/Dify/Di10.Step6：エージェントとツールーAIに行動させる.jpg)

### 図の要旨

* Agentは、必要に応じてツール（検索、DB、HTTP、社内APIなど）を呼び出して回答を完成させる。

### 詳細解説（用語）

* **Tool Calling / Function Calling**：LLMが「関数（ツール）を呼ぶべき」と判断し、引数を構造化して実行する仕組み。
* **ガードレール**：ツール実行の制限（許可ドメイン、回数、権限、PIIマスキング等）。

### Tips（実務）

* いきなり多ツールにしない。最初は「**1ツールだけ**」で安定させる。
* 社内システム連携は、**読み取り専用**から始める（更新系は事故が起きやすい）。

---

# 11. Step 7：テスト・デバッグ・ログ確認

![Di11.Step7：テストとデブッグーログ活用](/images/Dify/Di11.Step7：テストとデブッグーログ活用.jpg)

### 図の要旨

* Previewで動作確認し、ログ（RAGの拾い方、プロンプト、ツール呼び出し）を見て調整する。
* Previewのチャット回答の「ワークフロー処理」をクリックして**各ノードの①入力②データ処理③出力を確認**すると解決することが多い。

### 詳細解説（用語）

* **Trace**：1リクエストの実行経路（どのノードで何が起きたか）の記録。
* **評価観点**：正確性、根拠の妥当性、再現性、応答速度、コスト。

### Tips（実務：デバッグ手順）

1. まず「知識検索の結果（context）」が期待通りか
2. 次に「最終プロンプト」が意図通りか
3. それでもダメなら「文書・チャンク・閾値」を戻って調整

---

# 12. Step 8：公開（Webアプリ／共有／埋め込み）

![Di12.Step8：公開とデプロイーアプリを世界へ](/images/Dify/Di12.Step8：公開とデプロイーアプリを世界へ.jpg)

### 図の要旨

* Difyは作ったアプリをWebアプリとして公開し、URLで共有できる（埋め込みやAPI提供も可能）。

### 詳細解説（用語）

* **Embed**：自社サイトにチャットUIを埋め込む。
* **API**：バックエンドからDifyアプリを呼ぶ（社内ポータルから使う等）。

### Tips（実務）

* 公開前に最低限やる：

  * 個人情報が入力され得るなら **ログ保管方針**を決める
  * モデルAPIキー管理（漏洩・権限）を決める
  * 想定外入力（プロンプトインジェクション）への方針を入れる

---

# 13. Pro Tip：DSL（YAML）で共有・バックアップ

![Di13.ProTip：DSL（YAML）の活用ー共有とバックアップ](/images/Dify/Di13.ProTip：DSL（YAML）の活用ー共有とバックアップ.jpg)

### 図の要旨

* ワークフローをDSL（YAML）としてExport/Importでき、バックアップや他人のワークフロー学習に使える。

### 詳細解説（用語）

* **DSL（Domain Specific Language）**：特定用途の設定を表す言語。ここではWorkflow定義をYAMLで表現。
* **再現性**：同じYAMLを入れれば同じ構造が復元できる、という運用上の強み。

### Tips（実務）

* DSLを **Gitでバージョン管理**すると、変更履歴が追えてレビューもしやすい。
* 秘密情報（APIキー等）が混入しないよう、Export時の扱い・Secret管理を明確に。

---

# 14. Step 9：運用と改善（LLMOps）

![Di14.運用と改善（LLMOps）](/images/Dify/Di14.運用と改善（LLMOps）.jpg)

### 図の要旨

* 継続的改善は「監視（Monitor）→評価（Evaluate）→修正・注釈（Annotate）」のループで回す。

### 詳細解説（用語）

* **LLMOps**：LLMアプリを運用し、品質と安全性を継続的に改善する実務全般。
* **アノテーション**：回答が悪いケースを人間が修正し、次の改善データにする行為。

### Tips（実務：最小のLLMOps）

* まずは「失敗パターンを3分類」してチューニング対象を絞る

  1. 根拠不足（KB不足） 2) 検索失敗（チャンク/閾値） 3) プロンプト暴走（指示不足）
* “評価用の質問セット（10〜30問）” を作り、改善前後で比較する。

---

# 15. まとめ：開発・公開チェックリスト

![Di15.Summary：Dify開発と公開チェックリスト](/images/Dify/Di15.Summary：Dify開発と公開チェックリスト.jpg)

### 図の要旨

* Setup → RAG → Build → Test → Publish の順で進めるのが基本。
  そして運用（p14）で回し続ける。

### Tips（実務：MVPのゴール定義）

* **MVP成功条件**を先に決める（例：上位20質問の正答率80%、平均応答5秒以内、月コスト上限など）
* “正しく答えられない時のUX” を設計（不明、問い合わせ誘導、根拠提示）

---

# 付録：用語ミニ辞典（最低限・具体例つき）

> 目的：Dify/RAGを触る際に「何をどう調整すれば良いか」を、用語→具体例で結びつける。

---

## **RAG（Retrieval Augmented Generation）**

質問に対し、**社内文書などから関連箇所を検索（Retrieve）** して、その検索結果を **LLMの入力に追加して回答生成（Generate）** する方式。

### 具体例（会話での違い）

* **RAGなし**

  * Q:「休暇申請の締め日は？」
  * A:（モデルが推測してそれっぽく答える＝誤答リスク）

* **RAGあり**

  * Q:「休暇申請の締め日は？」
  * 検索：就業規則の該当ページを抽出
  * A:「就業規則第◯条より、締め日は毎月◯日です（出典: …）」のように **根拠付き**

### Tips（実務）

* RAGを使う目的は「賢くする」よりも **“根拠と再現性を持たせる”** こと。
* 最初の品質目標は「正答率」よりも **“根拠が出ないときに無理に答えない”** のほうが重要です。

---

## **Embedding（埋め込み）**

文章を、意味が近いほど距離が近くなる **ベクトル（数値配列）** に変換すること。RAGの検索は基本的にこのベクトル同士の近さで行う。

### 具体例（イメージ）

* 「パスワードを忘れた」
* 「ログインできない」
  → 文字は違うが意味が近いので、Embedding空間で近くなりやすい
  → 同じFAQチャンクがヒットしやすくなる

### Tips（実務）

* 日本語のRAGはEmbeddingの選定が効きます（同じ文書でも当たり方が変わる）。
* 「略語」「社内用語」「製品名」が多い文書は、Embeddingだけでは拾いにくいので、文書側に別名表記を足すと改善します。

---

## **Chunk（チャンク）**

RAG用に文書を分割した「検索単位」。チャンクは小さすぎても大きすぎても精度が落ちます。

### 具体例（分割の良し悪し）

* **悪い例（小さすぎ）**

  * 1チャンクが1文だけ
    → 前後文脈が欠け、回答に必要な条件が抜ける

* **悪い例（大きすぎ）**

  * 1チャンクが3ページ分
    → 関係ない情報も大量に混ざり、LLMが誤って拾う

* **良い例（目安）**

  * 見出し単位（例：`## 申請方法` のセクションごと）
  * 1チャンクが「規則 + 例外 + 手順」くらいのまとまり

### Tips（実務）

* FAQは「Q + A + 補足」を1チャンクにすると強い
* 手順書は「手順1〜5」など、**途中で切れない**単位が強い

---

## **TopK**

検索で返すチャンクの件数。多いほど情報は増えるが、ノイズも増える。

### 具体例（設定の考え方）

* `TopK=3`：根拠が少ないが、ノイズが減る
* `TopK=10`：根拠は増えるが、関係ない情報が混ざりやすい

### Tips（実務：症状→調整）

* 「根拠が出ない」→ TopKを **増やす**
* 「関係ない根拠が混ざる」→ TopKを **減らす**
* ただしTopKをいじる前に、**文書整形/チャンク改善**の方が効くことが多い

---

## **Score Threshold（スコア閾値）**

「この程度以上に近いチャンクだけを採用する」という足切りライン。

### 具体例（なぜ必要？）

* 関係ない文書でも、Embeddingの都合で「それなりに近い」扱いになる場合がある
  → スコア閾値を上げると、そうした“微妙に近いだけ”のノイズが減る

### Tips（実務：症状→調整）

* 「関係ない根拠が混ざる」→ 閾値を **上げる**
* 「根拠が全然出ない」→ 閾値を **下げる**
* 閾値を上げすぎると **contextが空**になりやすい
  → その場合に「不明」と言えるプロンプト設計が重要

---

## **Tool Calling（ツール呼び出し / Function Calling）**

LLMが「外部機能を呼ぶべき」と判断し、**APIや関数を実行して**回答を補強する仕組み。

### 具体例（想定シナリオ）

* ユーザー：「今日の障害チケット状況は？」
* LLM：チケットシステムAPIを呼ぶ
* API結果：`open=3, in_progress=5`
* LLM：「現在、未対応3件・対応中5件です」

### Tips（実務）

* まずは **読み取り専用ツール**から（更新系は事故が怖い）
* Tool Callingは「RAGで足りない“最新情報”」を補えるが、
  **権限・監査・PII（個人情報）**の設計が必須

---

## **LLMOps**

LLMアプリを運用しながら、ログ・評価・改善を回して品質を上げる実務全般。

### 具体例（最小のLLMOpsループ）

1. **Monitor**：ログで失敗例を集める（誤答/根拠不一致/回答拒否など）
2. **Evaluate**：代表質問セット（10〜30問）で定点評価する
3. **Improve**：改善を反映

   * 文書を足す / チャンクを直す / 閾値を調整 / プロンプトを修正
4. **Re-test**：改善前後で差分を確認

### Tips（実務）

* “正答率100%”を最初から狙うより、まずは
  **「根拠がないときに答えない」**＋**「根拠を必ず表示」**
  を徹底すると事故が激減します。
* 改善対象の分類（例）

  * KB不足（文書がない）
  * 検索失敗（チャンク/閾値/同義語）
  * 生成暴走（プロンプト不足）


