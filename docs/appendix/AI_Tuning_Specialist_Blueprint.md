# AIチューニングを解き明かす：専門家のための青写真
##description: 汎用LLMから特化型SLMへ。LLMaaS基盤、チューニング手法（Prompt/LoRA/QLoRA/Full）、OpenShift AIによる“工場化”、MLOps可観測性、AIレッドチーム、業界ユースケースまでを1枚ずつ解説（VitePress 1ファイル統合版）

## この資料の読み方（最重要）

この資料が言いたいことは、シンプルに次の3点です。

1. **汎用LLM（Generalist）をそのまま使う**だけでは、コスト/遅延/ガバナンスで壁に当たる
2. **特化型SLM（Small Language Model）＋効率チューニング（LoRA/QLoRA）**で、現場実装へ寄せる
3. チューニングは「作業」ではなく **MLOps×基盤で“工場化”**しないと、企業利用で回らない

> ゴール：モデル性能だけでなく、**運用・統制・セキュリティ込みで“ビジネス実装可能”なAI**にする。

---

# 1. 表紙：専門家のための青写真

![AIT1.AIチューニングを解き明かす専門家のための青写真](/images/LLM/AIT1.AIチューニングを解き明かす専門家のための青写真.jpg)

## 図の要旨

* 「AIチューニング」を、技術要素（手法・基盤・運用・セキュリティ）として分解し、実装までの道筋を示す
* “特化型AI” と “LLMaaS” をキーワードに、企業内で安全に回す未来像を描いている

## 用語（超基礎）

* **チューニング（Tuning）**：モデルの振る舞いを、目的（業務・ドメイン）に合わせて最適化する行為
* **LLMaaS（LLM as a Service）**：LLMを社内サービスとして提供し、アプリ側はAPIとして利用する形

## Tips（実務）

* 企業導入は「精度」だけで決まりません。**コスト、遅延、監査（誰が何を変えたか）、データ持ち出し禁止**が同じくらい重要です。

---

# 2. パラダイムシフト：汎用型から「特化型SLM」へ

![AIT2.パラダイムシフト：汎用型から「特化型SLM」へ](/images/LLM/AIT2.パラダイムシフト：汎用型から「特化型SLM」へ.jpg)

## 図の要旨

* 左：**汎用巨大モデル（Generalist）**は「高コスト・高レイテンシ・一般知識」寄り
* 右：**特化型SLM（例：tsuzumi）**は「軽量・低コスト・少ないGPUでも動く・日本語/業界特化」寄り
* “コストとエネルギー効率を両立して現場実装”が主テーマ

## 用語（超基礎）

* **SLM（Small Language Model）**：LLMより小規模で、特定用途に最適化しやすいモデル
* **レイテンシ（Latency）**：応答までの遅延（業務システムでは体感が強く効く）

## Tips（実務）

* 「汎用LLMを1つ選んで全社展開」は、だいたい詰まります。
  **業務ごとに“必要な賢さ”は違う**ので、SLMを混ぜるとコスト最適化しやすいです。

---

# 3. LLMaaSアーキテクチャ：企業のための生成AIハブ

![AIT3.LLMaaSアーキテクチャ：企業のための生成ＡＩハブ](/images/LLM/AIT3.LLMaaSアーキテクチャ：企業のための生成ＡＩハブ.jpg)

## 図の要旨

* アプリ（Tenant/User = AP Agent）が、社内の **LLMaaS Platform** を経由してモデルを使う
* 途中に **Trust/Safety Guardrails**（ガードレール）があり、危険な入力/出力を制御
* 基盤は **OpenShift AI** 上にあり、GPUノードや共有ストレージなどの“土台”を持つ
* API Gateway（例：Kong）が外部（アプリ）からの入口として機能するイメージ

## 用語（超基礎）

* **テナント（Tenant）**：組織/部署/プロジェクト単位の利用者区分（分離と課金/制御の単位になりやすい）
* **ガードレール（Guardrails）**：プロンプトインジェクションやPII漏洩などを止める防御レイヤ
* **API Gateway**：認証、ルーティング、レート制限、監査ログなど“入口の統制”を担う

## Tips（実務）

* 企業では「モデルを置く」だけでは足りません。**入口（認証/監査）と出口（ガードレール）**がないと、運用で事故ります。
* テナント分離（プロジェクトA/B）を意識すると、**機密データの境界**を作りやすいです。

---

# 4. チューニングのスペクトル：精度とリソースのトレードオフ

![AIT4.チューニングのスペクトル：精度とリソースのトレードオフ](/images/LLM/AIT4.チューニングのスペクトル：精度とリソースのトレードオフ.jpg)

## 図の要旨（3段階）

1. **Prompt Engineering**：最小コスト。プロンプト/指示で調整（汎用タスクに強い）
2. **PEFT（LoRA/QLoRA）**：中コスト。少ない学習でドメイン適応（現場の主戦場）
3. **Full Parameter Tuning**：高コスト。全パラメータ更新で最高精度（GPUクラスタ前提）

## 用語（超基礎）

* **PEFT（Parameter-Efficient Fine-Tuning）**：学習させるパラメータを最小化して、安価に適応させる手法群
* **ドメイン適応**：金融/製造/保険など、特定領域の言い回し・知識・形式に合わせること

## Tips（実務：選び方の目安）

* **まずPrompt**：仕様が固まり切ってない段階はこれが最速
* **次にLoRA/QLoRA**：要件が固まり、再現性を上げたい段階
* **Fullは最後**：どうしても最高精度が必要で、GPU/運用体制がある場合のみ

---

# 5. Deep Dive：フルパラメータ・チューニング（Brute Force）

![AIT5.DeepDive：フルパラメータチューニング](/images/LLM/AIT5.DeepDive：フルパラメータチューニング.jpg)

## 図の要旨

* Full Tuningは **VRAM消費が巨大**で、単一GPUではメモリ不足になりがち
* 解決：モデル/勾配/オプティマイザ状態を **クラスタ全体に分割（シャーディング）**
* 技術例：**PyTorch FSDP**、Hugging Faceの **SFTTrainer**

## 用語（超基礎）

* **VRAM**：GPUのメモリ。ここが足りないと学習が落ちる/そもそも動かない
* **FSDP（Fully Sharded Data Parallel）**：モデルを分割して複数GPUで学習する仕組み
* **SFT（Supervised Fine-Tuning）**：教師ありデータで「望む応答」を学習させる代表的手法

## 実務Tips（現場の落とし穴）

* Fullは「精度は出やすい」反面、**運用コスト（学習・再学習・監査）**が重い
* “とりあえずFull”にすると、後で**MLOps整備が追いつかず破綻**しやすいです

---

# 6. Deep Dive：LoRA（Low-Rank Adaptation）

![AIT6.DeepDive：LoRA（Low-RankAdaptation）](/images/LLM/AIT6.DeepDive：LoRA（Low-RankAdaptation）.jpg)

## 図の要旨

* 事前学習済み重み（Frozen）を大きく変えず、**小さな追加学習部品（Adapter）**を付ける
* **破滅的忘却（Catastrophic Forgetting）**を避けやすい
* 学習パラメータ数を **大幅削減（図では99%削減）**

## 用語（超基礎）

* **LoRA**：重み更新を“低ランク行列”に制限して、効率よく学習する手法
* **破滅的忘却**：新しい学習で既存能力が大きく失われる現象

## Tips（実務：LoRAが強い場面）

* 社内文書や業界文章の **言い回し・形式** に寄せたい（例：稟議、要約、FAQ回答）
* “モデル本体”を保ちつつ、**用途別にアダプタを差し替える**運用がしたい

### 実装例（イメージ：Hugging Face/PEFT）

```python
from peft import LoraConfig, get_peft_model
from transformers import AutoModelForCausalLM

base = AutoModelForCausalLM.from_pretrained("base-model")
lora = LoraConfig(r=8, lora_alpha=16, target_modules=["q_proj","v_proj"], lora_dropout=0.05)
model = get_peft_model(base, lora)
```

---

# 7. Deep Dive：QLoRA（Quantized LoRA）

![AIT7.DeepDive：QLoRA（QuantizedLow-RankAdaptation）](/images/LLM/AIT7.DeepDive：QLoRA（QuantizedLow-RankAdaptation）.jpg)

## 図の要旨

* モデルを **量子化（例：4-bit）**してVRAM使用量を削減しつつ、LoRAで学習
* “巨大モデルでも身近なGPUで回せる”方向へ（チューニングの民主化）

## 用語（超基礎）

* **量子化（Quantization）**：重みのビット幅を下げて軽量化する（例：16bit→4bit）
* **QLoRA**：量子化＋LoRAで、低VRAMでの学習/適応を狙う構成

## Tips（実務）

* QLoRAは強力ですが、環境差（GPU、ドライバ、CUDA）で詰まりやすいです。
  **“動く最小構成”をコンテナで固定**すると、チームで再現しやすくなります。

### 実装例（イメージ：必要ライブラリ）

```bash
pip install "transformers>=4.40" datasets peft bitsandbytes accelerate trl
```

---

# 8. エンジンルーム：Red Hat OpenShift AI（工場が必要）

![AIT8.エンジンルーム：RedHatOpenShiftAI](/images/LLM/AIT8.エンジンルーム：RedHatOpenShiftAI.jpg)

## 図の要旨

* チューニングは“作業台”ではなく、**スケールする工場（基盤）**が必要
* **Kubeflow Training Operator** などで学習ジョブを運用管理
* **MachineSetsでGPUノードを自動プロビジョニング（図では約20分）**

## 用語（超基礎）

* **Auto-scaling**：需要に応じて計算資源を増減
* **Provisioning**：必要なノード/資源を準備して使える状態にすること
* **MachineSet**：ノードの増減を“型”として管理する仕組み（自動化の鍵）

## Tips（実務）

* GPU調達より先に詰まるのは、だいたい **「誰がいつGPUを使うか」問題**です。
  → ジョブ管理（キュー）、利用枠、コスト可視化がセットになります。

---

# 9. MLOpsと可観測性：Weights & Biases（W&B）連携

![AIT9.MLOpsと可観測性：Weights＆Biasesとの連携](/images/LLM/AIT9.MLOpsと可観測性：Weights＆Biasesとの連携.jpg)

## 図の要旨

* 「測定できないものは改善できない」
* W&B連携で以下を実現：

  * **Training Traceability**（学習過程の追跡）
  * **Experiment Management**（実験管理）
  * **Governance**（誰が、いつ、何をチューニングしたか）

## 用語（超基礎）

* **可観測性（Observability）**：メトリクス/ログ/トレースで内部状態を説明できること
* **ガバナンス（Governance）**：変更の責任と証跡（監査に耐える運用）

## Tips（実務：最低限これだけは残す）

* データセットID（版）
* モデル/アダプタの版
* ハイパーパラメータ（lr, batch, epoch）
* 評価指標（lossだけでなく業務指標）

### 実装例（最小：学習ログをW&Bへ）

```bash
pip install wandb
wandb login
```

---

# 10. AIレディ・ネットワーク：製造現場（Factory 2.0）

![AIT10.AIレディネットワーク：製造現場（Factory2.0）](/images/LLM/AIT10.AIレディネットワーク：製造現場（Factory2.0）.jpg)

## 図の要旨

* ITとOTが融合し、工場のサーバ室が“ミニデータセンター化”
* Edge（現場）でリアルタイム推論・制御し、必要に応じて上位（クラウド/中枢）と連携する構図

## 用語（超基礎）

* **OT（Operational Technology）**：工場設備や制御システム領域
* **Edge**：現場近くで処理して、低遅延・安定稼働を狙う構成

## Tips（実務）

* 製造は「数秒遅い」が致命傷になり得ます。
  → **推論の配置（Edge/センター）とネットワーク設計**が、モデル選定と同じくらい重要です。

---

# 11. セキュリティとガバナンス：AIレッドチーム

![AIT11.セキュリティとガバナンス：AIレッドチーム](/images/LLM/AIT11.セキュリティとガバナンス：AIレッドチーム.jpg)

## 図の要旨

* 攻撃者視点で守る「オフェンシブ・セキュリティ」
* 代表リスク：**Prompt Injection / Bias / Data Poisoning**
* 手順：

  1. Attack Simulation（攻撃シミュレーション）
  2. Risk Discovery（リスク発見）
  3. Hardening（Guardrails強化）
* 機密データは **オンプレ/ハイブリッド内に保持**する前提

## 用語（超基礎）

* **Prompt Injection**：指示上書き（「前の指示を無視して…」）
* **Data Poisoning**：学習/評価データへの混入で挙動を歪める攻撃
* **Bias**：不公平な出力（差別・偏見・不適切な判断）

## Tips（実務）

* レッドチームは“1回やって終わり”にすると効きません。
  **成功した攻撃プロンプトを回帰テストに固定**し、継続的に当てるのが現場の勝ち筋です。

---

# 12. Case Study：製造業のサプライチェーン・レジリエンス（ORION）

![AIT12.CaseStudy：製造業におけるサプライチェーンレジリエンス](/images/LLM/AIT12.CaseStudy：製造業におけるサプライチェーンレジリエンス.jpg)

## 図の要旨

* 課題：設備故障などの突発変化で、計画が破綻する
* 解決：AIで **動的再計画**し、搬送/工程を自動で組み替える
* “Failure（詰まり）”が起きても、新ルートへ即時切替するイメージ

## 用語（超基礎）

* **レジリエンス（Resilience）**：壊れにくさ＋壊れても復旧できる力
* **再計画（Re-planning）**：条件変化に応じてスケジュールを作り直す

## Tips（実務）

* ここで重要なのは「LLMが賢い」より、**意思決定を実行へ落とす制御系（Agent/Workflow）**です。

---

# 13. Case Study：金融・保険の「デジタル従業員」

![AIT13.CaseStudy：金融保険における「デジタル従業員」](/images/LLM/AIT13.CaseStudy：金融保険における「デジタル従業員」.jpg)

## 図の要旨

* 単なるチャットボットではなく、**自律的に業務を遂行**する方向
* 例：

  * 複雑な保険金支払い資料の自動生成
  * 顧客リテラシーに合わせたパーソナライズ対話
  * Industry Tuned（業界特化）モデルの活用

## 用語（超基礎）

* **デジタル従業員**：対話だけでなく、書類作成・確認・段取りなど“作業”を担うAI
* **パーソナライズ**：相手に合わせて説明の粒度や表現を変えること

## Tips（実務）

* 金融/保険は「丁寧さ」より先に **説明責任（なぜそう判断したか）**が必要です。
  → 生成物の根拠提示（RAG）と監査ログが必須になります。

---

# 14. 未来への展望：Agentic AI（自律型AIエージェント）

![AIT14.未来への展望：AgenticAI（自律型エージェント）](/images/LLM/AIT14.未来への展望：AgenticAI（自律型エージェント）.jpg)

## 図の要旨

* 「Chat（対話）」から「Action（行動）」へ
* エージェントが、ERP/DB/SaaS/ロボティクス等と連携し、実行まで担う世界観
* 下段の3要素が揃うと回る：

  * Lightweight Models（特化型・効率）
  * Robust Platform（基盤）
  * Continuous Tuning（継続改善）

## 用語（超基礎）

* **Agentic AI**：意思決定→計画→実行（ツール呼び出し）まで含むAI
* **Continuous Tuning**：運用しながら評価・改善を続ける仕組み

## Tips（実務）

* “自律”は便利ですが、事故も増えます。
  → **権限（何を実行して良いか）**、**監査（誰が何をさせたか）**、**安全柵（Guardrails）**を先に設計してください。

---

# 15. 結論：専門家のための実装ブループリント

![AIT15.結論：専門家のための実装ブループリント](/images/LLM/AIT15.結論：専門家のための実装ブループリント.jpg)

## 図の要旨（4つの柱）

* Shift to Specialized：汎用から特化へ
* Efficient Tuning：LoRA/QLoRA等で効率化
* Industrial Platform：OpenShift AI等で工場化
* Secure Business Value：セキュリティと価値創出

最後の一言：

> **AIチューニングは魔法ではない。確実な技術戦略である。**

## 実務Tips（この資料を現場に落とすチェックリスト）

* [ ] 用途ごとに「汎用LLMで足りるか／特化SLMが要るか」を分けたか
* [ ] Prompt → LoRA/QLoRA → Full の順で、投資を段階化したか
* [ ] LLMaaSとして入口（API GW）と出口（Guardrails）を持ったか
* [ ] 学習/評価/デプロイの証跡（誰が何を変えたか）を残せるか
* [ ] レッドチーム（攻撃）を回帰テストとして運用できるか

---

## 付録：LLMaaS アーキテクチャ参考図（マルチテナント／Guardrails／推論基盤）
![AIT16.LLMaaS構成図（NTTデータ）](/images/LLM/AIT16.LLMaaS構成図（NTTデータ）.jpg)

この図は、企業内で **LLM（例：tsuzumi）を “LLMaaS（LLM as a Service）” として提供**する際の、代表的な構成イメージです。  
ポイントは **「ネットワーク分離（L3）× アプリ分離（L7）× 推論基盤（KServe/vLLM）× ガードレール（TrustyAI）× 監視」** を、テナント／プロジェクト単位で安全に運用できる形に落としていることです。

---

### 図の見方（まずここ）
- **左側**：利用者（Tenant/Project/User）とアプリ側（AP Agent）
- **中央左**：入口（Kong API Gateway）と、プロジェクト単位の L7 ルーティング（Ingress）
- **中央**：OpenShift 上の **Namespace（Project）分割**と、各プロジェクトの推論スタック
- **右側**：OpenShift クラスタ（Tenant）と、GPUノード（H100/B300 等）への接続
- **下段**：基盤（仮想化、IAサーバ、ストレージ）

---

### 1) リクエストの流れ（実際に“どう通るか”）
1. **ユーザー（Tenant/Project）** が、アプリ（AP Agent）に依頼  
2. アプリは社内の通信経路（FW/L3スイッチ等）を通って **Kong API Gateway** へ到達  
3. Kongで **認証・認可・監査・レート制限** を行い、ルート（例：`/projectA`）で振り分け  
4. **Ingress Controller** がプロジェクト別のバックエンドへ転送（L7分離）  
5. プロジェクト（Namespace）内で、
   - **TrustyAI Guardrails**（入力/出力の安全柵）
   - **推論サービス（KServe）**
   - **モデルサーバ（vLLM）＋モデル（例：tsuzumi）**
   が連携して推論を実行  
6. 推論はCPUノードだけでなく、必要に応じて **GPUノード（H100/B300 等）** を利用  
7. 応答がアプリへ戻り、ユーザーへ返却

> **要点**：入口（Kong）で“統制”、プロジェクト内で“推論”、前後（Guardrails）で“事故防止”。

---

### 2) 分離の考え方（L3 と L7 を両方やる理由）
図中にある「分離」は2種類あります。

- **テナント間 L3 分離（ネットワーク分離）**  
  - Tenant1 と Tenant2 を、ネットワーク的に分ける（別世界にする）  
  - 目的：**組織間の境界**、重要データの隔離、誤到達の防止

- **プロジェクト間 L7 分離（アプリ分離）**  
  - 同一テナント内でも `Project A / Project B` を URL/Host 等で分ける  
  - 目的：**サービス単位の独立運用**、段階リリース、障害影響の局所化

> **使い分けの直感**：  
> L3＝「別会社/別部門レベルの境界」  
> L7＝「同じ会社の中の別システム境界」

---

### 3) 推論スタックの役割（TrustyAI／KServe／vLLM）
プロジェクト（Namespace）内の箱は、だいたい役割が固定です。

- **TrustyAI Guardrails**  
  - 目的：入力/出力の安全性と品質を“強制”する  
  - 例：PII（個人情報）マスキング、禁止話題ブロック、根拠なし断定抑制、形式（JSON）強制

- **KServe（推論サービス）**  
  - 目的：推論APIをサービスとして提供し、スケールやデプロイを管理  
  - 例：モデルの差し替え（A/B）、オートスケール、リビジョン管理

- **vLLM（モデルサーバ）**  
  - 目的：LLM推論の高速化（特にスループットとGPU効率）  
  - 例：同時リクエストが増えても、キューイングやバッチングで効率化

---

### 4) 運用・監視（“止まった”を止めない）
図のTenant領域にある「監視・セキュリティ系ソフト（例：HinemOS/Grafana等）」は、
**“品質”ではなく “運用” を守る**ための要です。

- **遅延（Latency）**：レスポンスが遅い＝業務利用で致命傷  
- **GPU使用率**：GPUが遊んでいる/詰まっているを可視化  
- **失敗率（5xx/Timeout）**：推論基盤の劣化を早期検知  
- **監査ログ**：誰がどのテナントで何を呼んだか（セキュリティ監査）

---

### 5) 実務Tips（ここで詰まりやすいポイント）
- **(Tip1) 入口は“統制の中心”**  
  Kongに「認証」「レート制限」「監査ログ」を寄せると、後から事故調査ができます。

- **(Tip2) Namespace分割は“権限設計”とセット**  
  Project A/B を分けても、RBACやSecret管理が甘いと“境界が溶ける”ので注意。

- **(Tip3) Guardrailsは“拒否＋代替提示”が正解**  
  ブロックだけだと現場の不満が増えます。  
  例：PIIを伏字化して継続、危険手順は一般論へ誘導、根拠不足は確認質問へ切替。

- **(Tip4) GPUは“速い”より“枯渇する”が問題**  
  同時アクセスが増えると、GPUがボトルネック化します。  
  → クォータ、同時実行制限、優先度（重要ジョブ優先）を決めると運用が安定します。

- **(Tip5) アウトバウンドは最小（例：443/TCP）に寄せる**  
  閉域網では“外へ出る経路”が最小・監査対象になりやすいので、  
  更新・運用のための通信設計（許可先、証明書、プロキシ）を最初に固めると後工程が楽です。

---
```

