## 1. ガイド全体の狙い
![Dif1.Difyよくある失敗パターンとパラメータ調整ガイド](/images/Dify/Dif1.Difyよくある失敗パターンとパラメータ調整ガイド.jpg)
### 図の要旨
- この資料は、DifyのRAG/LLMアプリで発生する不具合や品質問題を **「どこで壊れるか」→「何を調整するか」** の観点で整理した“現場用の早見表”です。
- ポイントは、**一気に色々変えず、原因仮説を立てて 1つのパラメータだけを動かす**こと（重要：原因が見えなくなることを防ぎます。）

### 詳細解説（用語）
- **RAG**：Retrieval Augmented Generation。検索で得た根拠（コンテキスト）をLLMに渡して回答させる方式。
- **パラメータ（調整弁）**：設定値を変えることで挙動を意図的に変えるレバー。チャンク長、TopK、閾値、Temperatureなど。

### Tips（実務）
- 最初に「再現できる質問セット（3〜10問）」を作る → 以後その質問だけで比較。
- “良い/悪い”の判断基準を固定（正答率/引用の妥当性/コスト/レイテンシ）し、メトリクスを残す。

---
## 2. 失敗の解剖学：AIアプリはどこで壊れるのか
![Dif2.失敗の解剖学：AIアプリはどこで壊れるのか？](/images/Dify/Dif2.失敗の解剖学：AIアプリはどこで壊れるのか？.jpg)
### 図の要旨
- Difyの典型的な流れは **ユーザー入力 →（必要なら）知識検索 → LLM → 回答**。
- 失敗は大きく (1)入力、(2)検索、(3)コンテキスト連携、(4)生成、(5)運用（コスト/制限）に分解できます。

### 詳細解説（用語）
- **知識検索（Knowledge Search）**：ナレッジベースから関連チャンクを取り出すノード。RAGの“R”の部分。
- **コンテキスト**：知識検索で取れた根拠テキスト。LLMプロンプトに変数として差し込む必要がある。

### Tips（実務）
- デバッグは「検索が取れてない」のか「検索は取れてるがLLMに渡せてない」のかを分離するのが最短です。
- まず知識検索ノード単体の「最後の実行」出力で result が埋まっているかを見る。

---
## 3. 失敗パターン①：コンテキストが欠ける/切れる（チャンク設計）
![Dif3.失敗パターン１：情報の「文脈」が寸断されている](/images/Dify/Dif3.失敗パターン１：情報の「文脈」が寸断されている.jpg)
### 図の要旨
- チャンクが **小さすぎる**と、1つのチャンクに必要な情報が入りきらず“断片”しか当たりません。
- チャンクが **大きすぎる**と、検索は当たっても関係ない文章が混ざり、LLMが要点を外しやすくなります。
- オーバーラップ（重なり）は、章またぎの情報を拾うための保険です。

### 詳細解説（用語）
- **チャンク（chunk）**：文書を検索用に分割した最小単位。検索はチャンク単位で返る。
- **最大チャンク長**：チャンクの上限（文字数/トークン相当）。Dify画面では characters。
- **オーバーラップ**：隣接チャンク同士を重ねる文字数。章境界で情報が割れないようにする。
- **親子分割（Parent-child）**：検索用の“小チャンク”と、LLMに渡す“大チャンク”を分ける方式。精度と文脈の両取り。

### Tips（実務）
- 目安：**最大チャンク長 600〜1200 chars**、オーバーラップは **10〜25%（例：80〜200 chars）** から開始。
- “手順書/規約”のように章立てが強い文書は、見出しで切れるように改行区切りを活かし、必要なら親子分割を検討。

---
## 4. 失敗パターン②：文書があるのに見つからない（ゴースト文書）
![Dif4.失敗パターン２：あるはずの情報が見つからない「ゴーストドキュメント」](/images/Dify/Dif4.失敗パターン２：あるはずの情報が見つからない「ゴーストドキュメント」.jpg)
### 図の要旨
- アップロードしたはずの文書が検索に出ない場合、(a) インデックス作成が失敗/未完了、(b) インデックス方式が粗い、(c) 埋め込みモデル不一致/未設定、が典型です。
- “経済的”インデックスは速度/コスト優先で、精度が落ちることがあります。まずは“高品質”で安定させるのが安全。

### 詳細解説（用語）
- **インデックス**：検索できるように文書をベクトル化/転置化して登録したデータ。
- **埋め込みモデル（Embedding）**：文章→ベクトル（意味の座標）に変換するモデル。RAGの検索品質の土台。
- **高品質/経済的**：Difyのインデックス方式の選択肢。高品質は精度重視、経済的はコスト/速度重視。

### Tips（実務）
- まずは **高品質 + ベクトル検索** で成立させる → その後、データ量が増えてから経済的/ハイブリッドを検討。
- モデル変更後は「再インデックス（再作成）」が必要になることがある（古いベクトルのままだと一致しない）。

---
## 5. 失敗パターン③：ノイズが多すぎて回答がブレる
![Dif5.失敗パターン３：ノイズ過多による混乱](/images/Dify/Dif5.失敗パターン３：ノイズ過多による混乱.jpg)
### 図の要旨
- TopKを増やしたりチャンクが大きいと、関係ないチャンクまで混ざり、LLMが“それっぽい別回答”を作りやすくなります。
- この場合は **スコア閾値**を上げて、一定以上の類似度のチャンクだけを残すと安定します。

### 詳細解説（用語）
- **スコア閾値**：検索スコアがこの値未満のチャンクを捨てるフィルタ。Precision（精度）を上げる。
- **Precision / Recall**：Precision=当たったものの正しさ、Recall=拾える量。閾値↑はPrecision↑/Recall↓。

### Tips（実務）
- 目安：まず閾値は **0.0〜0.3（緩め）** → ノイズが多いなら **0.5** → 法規/マニュアルで厳密なら **0.7** も検討。
- 閾値を上げる前に、チャンク設計（p03）とTopK（p06）を“常識範囲”に戻すのが先。

---
## 6. 失敗パターン④：答えがあるのに1歩届かない
![Dif6.失敗パターン４：あと一歩で情報が届かない](/images/Dify/Dif6.失敗パターン４：あと一歩で情報が届かない.jpg)
### 図の要旨
- “たまに答えが出る/出ない”のような症状は、検索候補が少なく **TopK** が足りていないケースが多いです。
- TopKを上げるとRecallは上がりますが、ノイズも増えるので p05 の閾値とセットで調整します。

### 詳細解説（用語）
- **TopK**：検索で返すチャンク数。K=3なら上位3件。

### Tips（実務）
- 目安：小規模ナレッジ（数十〜数百チャンク）なら **K=3〜5**。中規模なら **K=5〜10**。
- TopKを上げたら、必要なら閾値も少し上げてノイズを抑える（例：K=8 & 閾値=0.3）。

---
## 7. 発展：Rerankで「当たり」を上位に引き上げる
![Dif7.上級編：検索制度の限界を突破する「Rerank」](/images/Dify/Dif7.上級編：検索制度の限界を突破する「Rerank」.jpg)
### 図の要旨
- ハイブリッド検索（キーワード+ベクトル）で広く候補を集め、**Rerank**で“質問に最も効くチャンク”を再順位付けする方式です。
- 日本語はキーワード一致が効く場面（固有名詞/略語）が多いので、ハイブリッド+Rerankは効きやすいです。

### 詳細解説（用語）
- **ハイブリッド検索**：全文検索（BM25等）とベクトル検索を同時に使う。
- **Rerank**：候補チャンク集合を、別モデルで再スコアリングして順位を付け直す。
- **候補K（Stage1）/採用K（Stage2）**：まず多めに集め（例10件）、上位だけ採用（例3件）する。

### Tips（実務）
- Rerankは“精度ブースター”ですが、APIコストとレイテンシが増えます。まずはRerank無しで成立→最後に導入が安全。
- Rerank導入時は、Stage1のKを増やし（例：10〜20）、採用Kは3〜5に絞ると安定。

---
## 8. 失敗パターン⑤：検索結果がLLMに渡っていない（変数差し込みミス）
![Dif8.失敗パターン５：変数の「手入力」による切断](/images/Dify/Dif8.失敗パターン５：変数の「手入力」による切断.jpg)
### 図の要旨
- 知識検索が成功していても、LLMノードのSYSTEM/USERに **変数として挿入**していないと、LLMは検索結果を見ていません。
- “画面に見える文字列”を手入力しただけだと、Jinjaテンプレートが評価されず、ただの文字列扱いで失敗します。

### 詳細解説（用語）
- **変数挿入**：Difyの {x} ボタン等で、ノード出力（例：knowledge_search.result）をプロンプトに差し込む操作。
- **Jinja**：Difyが内部で使うテンプレート。<code v-pre>{{ ... }}</code> の形で変数を参照する。

### Tips（実務）
- 最短チェック：LLMノードの「最後の実行」で、SYSTEMに渡った最終プロンプト（render後）が“検索結果入り”かを確認。
- 知識検索ノードの出力変数名が `result` なのか `context` なのかは、ノード種別/バージョンで違うので、{x}から選択するのが安全。

---
## 9. 失敗パターン⑥：ハルシネーション（それっぽい嘘）
![Dif9.失敗パターン６：AIが「もっともらしい嘘」をつく](/images/Dify/Dif9.失敗パターン６：AIが「もっともらしい嘘」をつく.jpg)
### 図の要旨
- RAGでも、温度が高い/プロンプトが緩いと、LLMが“空白を想像で埋める”ことがあります。
- 対策は、(a) Temperatureを下げる、(b) コンテキスト優先を強制する、(c) 足りなければ「ナレッジに記載がありません」と返す、です。

### 詳細解説（用語）
- **Temperature**：出力のランダム性。低いほど決定的（同じ質問で同じ回答になりやすい）。
- **ハルシネーション**：根拠のない内容をもっともらしく生成すること。

### Tips（実務）
- RAGの目安：Temperature **0.2〜0.4**（安定と自然さのバランス）。
- “2段構え”（ナレッジ回答→一般論補足）をする場合も、**一般論は一般論として明示**し、ナレッジと混ぜない。

---
## 10. 失敗パターン⑦：回答が途中で切れる
![Dif10.失敗パターン７：回答が途中で途切れる](/images/Dify/Dif10.失敗パターン７：回答が途中で途切れる.jpg)
### 図の要旨
- 手順が長い/引用が多いと、出力トークン上限（Max tokens）に当たって途中で止まることがあります。
- この場合は（Max tokens）を上げるか、回答フォーマット（箇条書き/要約）を強制して短くします。

### 詳細解説（用語）
- **Max tokens**：LLMが出力できる最大トークン数。
- **トークン**：LLMの内部単位（日本語は文字数と1:1ではない）。

### Tips（実務）
- 目安：短いQAなら 256〜512、説明文なら 800〜1200、手順書なら 1500〜2500 もあり得る。
- まずは“要約→詳細”の2段（短文で出して続きはユーザーが要求）にすると、コストも抑えやすい。

---
## 11. 失敗パターン⑧：429（レート制限）で落ちる
![Dif11.失敗パターン８：ピーク時にシステムが停止する（429_Error）](/images/Dify/Dif11.失敗パターン８：ピーク時にシステムが停止する（429_Error）.jpg)
### 図の要旨
- アクセス集中や無料枠/制限で、モデルプロバイダが 429 を返すことがあります。
- 対策は、(a) APIキーを複数登録して分散、(b) リトライ+指数バックオフ、(c) 同時実行数を下げる、です。

### 詳細解説（用語）
- **429**：Too Many Requests。一定時間内のリクエスト数が上限を超えた。
  - FreePlanなどでよく遭遇、待ちたくない場合はLLMのモデルを変えるだけでも一時しのぎになる。（この制限はモデル単位であることが多い）  
- **バックオフ**：失敗時に待ち時間を徐々に増やすリトライ方式。

### Tips（実務）
- 障害対応では、まず“いつ/何回/どのノードで”429が出たかをログで把握する（p13）。
- Rerankを入れている場合、裏で追加コールが増えるので429が出やすくなる点に注意。

---
## 12. 失敗パターン⑨：コストが急増する
![Dif12.失敗パターン９：請求額の予期せぬ高騰](/images/Dify/Dif12.失敗パターン９：請求額の予期せぬ高騰.jpg)
### 図の要旨
- 原因の多くは、(a) TopK/チャンクが大きくてコンテキストが肥大化、(b) 高価なモデルを全ノードで使っている、(c) Rerank等で呼び出し回数が増えている、のいずれかです。
- ノードごとに“どれだけトークンを食ったか”を見て、コストの主因を特定します。

### 詳細解説（用語）
- **トークン課金**：入力トークン+出力トークンで課金されるモデルが多い。コンテキストが長いほど入力課金↑。

### Tips（実務）
- 原則：**検索（R）と生成（G）で役割分担**。生成は小〜中モデル（Flash等）で十分なことが多い。
- 評価質問セットで、コスト/正確性のトレードオフを見ながら段階的に。

---
## 13. デバッグの最短ルート：ログと変数検査
![Dif13.デブッグの極意：ログは「嘘」をつかない](/images/Dify/Dif13.デブッグの極意：ログは「嘘」をつかない.jpg)
### 図の要旨
- “ナレッジに記載がありません”が出た時は、(1)検索に当たっていない、(2)当たっているがLLMに渡っていない、(3)渡っているがプロンプトが壊れている、の3択です。
- このページは、どこを見れば切り分けできるか（変数・ログ）を示します。

### 詳細解説（用語）
- **変数検査**：各ノードの入出力（query/result/contextなど）を確認して、どこで欠落したかを見ること。

### Tips（実務）
- 知識検索ノード：`result` が空なら検索側。`result` が埋まっているならLLM側（変数差し込み or プロンプト）。
- LLMノード：SYSTEMのrender結果に検索結果が入っているか確認（8章）。

---
## 14. 症状→原因→調整弁のマトリクス
![Dif14.パラメータ調整マトリックス（TheTuningMatrix）](/images/Dify/Dif14.パラメータ調整マトリックス（TheTuningMatrix）.jpg)
### 図の要旨
- 現場で迷うのは“何から触るか”。このページは、症状ごとに優先して触る設定を整理した表です。
- 重要なのは **順番** で、まず **“入力→検索→連携→生成”** の順に疑うと遠回りしません。

### 詳細解説（用語）
- **調整順**：1つずつ変えるための“安全な順番”。

### Tips（実務）
- おすすめ順：①インデックス成功/ナレッジ選択 → ②変数差し込み → ③チャンク設計 → ④TopK → ⑤閾値 → ⑥Rerank → ⑦Temperature/Max tokens。

---
## 15. 本番化ロードマップ
![Dif15.プロダクションへの道（TheRoadToProduct）](/images/Dify/Dif15.プロダクションへの道（TheRoadToProduct）.jpg)
### 図の要旨
- 最後に、検証から本番運用へ移る時に必要な観点（監視/コスト/品質維持）が整理されています。
- PoCで終わらせず、運用できる形に落とすためのチェックリストと捉えると良いです。

### 詳細解説（用語）
- **本番化**：安定稼働（エラー率・遅延・コスト・品質）を一定水準で維持できる状態。

### Tips（実務）
- 運用では“設定値の履歴”が資産になります。変更ログ（いつ何をいじったか）を残す仕組みを用意する。
- ユーザーからのフィードバック（誤答例）を質問セットに追加し、回帰テストのように使う。

---
## 補足：パラメータ（調整弁）大全
> ここは“今回の資料に出ていないものも含めて”、RAG品質と運用に効く代表パラメータを整理します。

### １） チャンク関連（分割・前処理）
- **最大チャンク長（characters）**
  - 役割：検索単位の“粒度”を決める。
  - 小さすぎ：断片化→必要情報が別チャンクに散る→取りこぼし（Recall↓）。
  - 大きすぎ：ノイズ混入→回答がブレる（Precision↓）＆入力トークン増→コスト↑。
  - 目安：
    - FAQ/短文：300〜700
    - マニュアル/社内規程：700〜1400
    - 会話ログ/長文：親子分割を検討（下記）。
- **オーバーラップ（characters）**
  - 役割：章境界で情報が割れるのを防ぐ。
  - 目安：最大チャンク長の10〜25%（例：800なら80〜200）。
- **チャンク識別子（区切り）**
  - 役割：どこで分割するかのルール。Markdownなら `\n\n`（段落）や見出し単位が効く。
  - Tips：見出し（`#`/`##`）の直後で切ると“意味のまとまり”が保たれやすい。
- **前処理（連続スペース/改行置換、URL削除など）**
  - 役割：ノイズを減らす。URLを削除すると引用リンクが必要な用途では逆効果。
- **親子分割（Parent-child / 階層分割）**
  - 役割：検索は小チャンクで当て、LLMには親（大チャンク）を渡して文脈不足を防ぐ。
  - 使いどころ：規程/手順/議事録のように“章全体”が必要な文書。

### ２） インデックス・埋め込み関連
- **インデックス方式（高品質 / 経済的）**
  - 高品質：精度優先。まずこちらで成立させる。
  - 経済的：コスト/速度優先。データ量が増えたら検討。
- **埋め込みモデル（Embedding Model）**
  - 役割：意味の近さで検索できるかを決める“土台”。
  - 注意：埋め込みモデルを変えたら、既存ベクトルは別空間になるため、再インデックスが必要になり得る。
- **メタデータ（タグ/カテゴリ/部署/日付など）**
  - 役割：検索対象を絞り、ノイズを減らす。FAQが複数領域ある場合に強力。

### ３） 検索（Retriever）関連：TopK / 閾値 / 検索モード
- **検索モード**
  - ベクトル検索：意味検索。言い換えに強い。
  - 全文検索：キーワード一致（**BM25**/TF-IDF等）。固有名詞/型番/コードに強い。
  - ハイブリッド検索：両方を併用。多くの業務文書で最終的に強いが、設定が増える。
- **TopK**
  - 役割：「検索で拾ってくる“候補チャンクの数”」。
    - 1) Recall↑（拾い漏れが減る）
      - 答えが入っているチャンクが 上位3に入らないことがあります。
      - TopKを増やすと、答えが 上位10とか20に含まれる確率が上がる＝拾い漏れが減る、という意味です
    - 2) ノイズ↑（関係ないチャンクも混ざる）
      - TopKを増やすと、後半の候補は「そこそこ近い」程度なので、関係ないチャンクが混ざりやすくなります。
      - LLMは混ざった情報も読んでしまうので、余計な話をし始める、断定がぶれるなど。
      - 「ナレッジにない」判定が曖昧になる
    などが起きやすくなります。

    - 3) コスト↑（トークン増＝遅い/高い）
      - TopKが増えるほど、LLMに渡すコンテキストが増えます。
      - その分 トークン消費・応答時間・料金が上がります。
      - 目安：
        - 小（〜数百チャンク）：3〜5
        - 中（〜数万チャンク）：5〜10
        - 大：10〜20（Rerank併用推奨）
- **スコア閾値**
  - 役割：低品質候補を捨てるフィルタ。Precision↑/Recall↓。
  - 目安：0.0〜0.3（緩め）→0.5（標準）→0.7（厳密）
- **セマンティクス vs キーワードの重み**（ハイブリッド時）
  - 役割：意味一致を重視するか、語一致を重視するか。
  - 使い分け：
    - 仕様書/規程：セマンティクス寄り（0.7〜1.0）
    - 型番/製品名/エラーコード：キーワード寄り（0.4〜0.6）
- **Rerank**
  - 役割：候補集合から“質問に最適”を選び直す。Precisionが大幅に上がることがある。
  - 代償：追加APIコール（コスト/遅延/429リスク）。

### ４） LLM生成（Generator）関連：Temperature / Top-p / Max tokens
- **Temperature**
  - 役割：ランダム性（創造性）を調整。
  - 目安：
    - RAG/業務QA：0.2〜0.4
    - ブレスト/文章生成：0.7〜1.0
  - 作用：高いほど“それっぽい補完”が増え、ハルシネーション率が上がりやすい。
- **Top-p（nucleus sampling）**
  - 役割：確率上位pの候補からサンプリング。Temperatureと同様に多様性を調整。
  - 目安：RAGは0.8〜1.0（固定）で温度だけ触る運用が多い。
- **Max tokens（出力上限）**
  - 役割：回答が途中で切れないようにする。
  - 目安：説明なら800〜1500、手順書なら1500〜2500も検討。
- **System Prompt（SYSTEM）**
  - 役割：回答ポリシーを強制する最重要パラメータ。
  - Tips：『根拠はコンテキストのみ』『無ければ“ナレッジに記載がありません”』のように明文化。

### ５） コンテキスト連携（変数）と“2段構え”
- **コンテキスト変数の挿入**
  - 原則：手入力せず、Difyの {x} からノード出力を挿入する。
  - よくある事故：<code v-pre>{{ ... }}</code> を手で打ってJinja評価されず、検索結果が空扱い。
- **2段構え（推奨パターン）**
  - 目的：ハルシネーションを抑えつつ、ナレッジ外の一般論で“補足”も提供する。
  - 例：
    1) 【ナレッジ回答】…コンテキストがあればそこから回答＋引用
    2) 【一般論（補足）】…ナレッジに無い場合でも、一般的な説明を短く（ただし“推測”である旨を明示）
  - 注意：一般論を“ナレッジに書いてあった”ように言わない。

### ６） 運用・信頼性（429/タイムアウト/コスト）
- **リトライ設定**：一時障害（429/503）に強くなるが、遅延とコストが増える。
- **同時実行数**：上げるほど速いが、429に当たりやすい。
- **キー分散**：複数キー登録でピークをならす（プロバイダ規約は遵守）。
- **コスト監視**：ノード別トークン、TopK・チャンク長・Rerank有無が主因になりやすい。

### ７） よくある“症状別”クイック処方箋
- **『ナレッジに記載がありません』ばかり**：①知識検索ノードの出力resultが空か確認 → 空なら検索設定/インデックス、埋まっているならLLMへの変数差し込み（8章）。
- **たまに当たる/たまに外す**：TopKを+2〜+5（6章）、必要なら閾値を0.2〜0.4へ。
- **関係ない引用が混ざる**：閾値を上げる（5章）、チャンク長を下げる（3章）。
- **回答が長すぎ/遅い/高い**：チャンク長を下げる、TopKを下げる、Rerankを外す（12章）。
- **嘘っぽい**：Temperatureを0.2〜0.4へ、SYSTEMで根拠限定（9章）。
