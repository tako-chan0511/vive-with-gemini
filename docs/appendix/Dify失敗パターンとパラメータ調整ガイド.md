## 1. ガイド全体の狙い
![Dif1.Difyよくある失敗パターンとパラメータ調整ガイド](/images/Dify/Dif1.Difyよくある失敗パターンとパラメータ調整ガイド.jpg)
### 図の要旨
- この資料は、DifyのRAG/LLMアプリで発生する不具合や品質問題を **「どこで壊れるか」→「何を調整するか」** の観点で整理した“現場用の早見表”です。
- ポイントは、**一気に色々変えず、原因仮説を立てて 1つのパラメータだけを動かす**こと（重要：原因が見えなくなることを防ぎます。）

### 詳細解説（用語）
- **RAG**：Retrieval Augmented Generation。検索で得た根拠（コンテキスト）をLLMに渡して回答させる方式。
- **パラメータ（調整弁）**：設定値を変えることで挙動を意図的に変えるレバー。チャンク長、TopK、閾値、Temperatureなど。

### Tips（実務）
- 最初に「再現できる質問セット（3〜10問）」を作る → 以後その質問だけで比較。
- “良い/悪い”の判断基準を固定（正答率/引用の妥当性/コスト/レイテンシ）し、メトリクスを残す。

---
## 2. 失敗の解剖学：AIアプリはどこで壊れるのか
![Dif2.失敗の解剖学：AIアプリはどこで壊れるのか？](/images/Dify/Dif2.失敗の解剖学：AIアプリはどこで壊れるのか？.jpg)
### 図の要旨
- Difyの典型的な流れは **ユーザー入力 →（必要なら）知識検索 → LLM → 回答**。
- 失敗は大きく (1)入力、(2)検索、(3)コンテキスト連携、(4)生成、(5)運用（コスト/制限）に分解できます。

### 詳細解説（用語）
- **知識検索（Knowledge Search）**：ナレッジベースから関連チャンクを取り出すノード。RAGの“R”の部分。
- **コンテキスト**：知識検索で取れた根拠テキスト。LLMプロンプトに変数として差し込む必要がある。

### Tips（実務）
- デバッグは「検索が取れてない」のか「検索は取れてるがLLMに渡せてない」のかを分離するのが最短です。
- まず知識検索ノード単体の「最後の実行」出力で result が埋まっているかを見る。

---
## 3. 失敗パターン①：コンテキストが欠ける/切れる（チャンク設計）
![Dif3.失敗パターン１：情報の「文脈」が寸断されている](/images/Dify/Dif3.失敗パターン１：情報の「文脈」が寸断されている.jpg)
### 図の要旨
- チャンクが **小さすぎる**と、1つのチャンクに必要な情報が入りきらず“断片”しか当たりません。
- チャンクが **大きすぎる**と、検索は当たっても関係ない文章が混ざり、LLMが要点を外しやすくなります。
- オーバーラップ（重なり）は、章またぎの情報を拾うための保険です。

### 詳細解説（用語）
- **チャンク（chunk）**：文書を検索用に分割した最小単位。検索はチャンク単位で返る。
- **最大チャンク長**：チャンクの上限（文字数/トークン相当）。Dify画面では characters。
- **オーバーラップ**：隣接チャンク同士を重ねる文字数。章境界で情報が割れないようにする。
- **親子分割（Parent-child）**：検索用の“小チャンク”と、LLMに渡す“大チャンク”を分ける方式。精度と文脈の両取り。

### Tips（実務）
- 目安：**最大チャンク長 600〜1200 chars**、オーバーラップは **10〜25%（例：80〜200 chars）** から開始。
- “手順書/規約”のように章立てが強い文書は、見出しで切れるように改行区切りを活かし、必要なら親子分割を検討。

---
## 4. 失敗パターン②：文書があるのに見つからない（ゴースト文書）
![Dif4.失敗パターン２：あるはずの情報が見つからない「ゴーストドキュメント」](/images/Dify/Dif4.失敗パターン２：あるはずの情報が見つからない「ゴーストドキュメント」.jpg)
### 図の要旨
- アップロードしたはずの文書が検索に出ない場合、(a) インデックス作成が失敗/未完了、(b) インデックス方式が粗い、(c) 埋め込みモデル不一致/未設定、が典型です。
- “経済的”インデックスは速度/コスト優先で、精度が落ちることがあります。まずは“高品質”で安定させるのが安全。

### 詳細解説（用語）
- **インデックス**：検索できるように文書をベクトル化/転置化して登録したデータ。
- **埋め込みモデル（Embedding）**：文章→ベクトル（意味の座標）に変換するモデル。RAGの検索品質の土台。
- **高品質/経済的**：Difyのインデックス方式の選択肢。高品質は精度重視、経済的はコスト/速度重視。

### Tips（実務）
- まずは **高品質 + ベクトル検索** で成立させる → その後、データ量が増えてから経済的/ハイブリッドを検討。
- モデル変更後は「再インデックス（再作成）」が必要になることがある（古いベクトルのままだと一致しない）。

---
## 5. 失敗パターン③：ノイズが多すぎて回答がブレる
![Dif5.失敗パターン３：ノイズ過多による混乱](/images/Dify/Dif5.失敗パターン３：ノイズ過多による混乱.jpg)
### 図の要旨
- TopKを増やしたりチャンクが大きいと、関係ないチャンクまで混ざり、LLMが“それっぽい別回答”を作りやすくなります。
- この場合は **スコア閾値**を上げて、一定以上の類似度のチャンクだけを残すと安定します。

### 詳細解説（用語）
- **スコア閾値**：検索スコアがこの値未満のチャンクを捨てるフィルタ。Precision（精度）を上げる。
- **Precision / Recall**：Precision=当たったものの正しさ、Recall=拾える量。閾値↑はPrecision↑/Recall↓。

### Tips（実務）
- 目安：まず閾値は **0.0〜0.3（緩め）** → ノイズが多いなら **0.5** → 法規/マニュアルで厳密なら **0.7** も検討。
- 閾値を上げる前に、チャンク設計（p03）とTopK（p06）を“常識範囲”に戻すのが先。

---
## 6. 失敗パターン④：答えがあるのに1歩届かない
![Dif6.失敗パターン４：あと一歩で情報が届かない](/images/Dify/Dif6.失敗パターン４：あと一歩で情報が届かない.jpg)
### 図の要旨
- “たまに答えが出る/出ない”のような症状は、検索候補が少なく **TopK** が足りていないケースが多いです。
- TopKを上げるとRecallは上がりますが、ノイズも増えるので p05 の閾値とセットで調整します。

### 詳細解説（用語）
- **TopK**：検索で返すチャンク数。K=3なら上位3件。

### Tips（実務）
- 目安：小規模ナレッジ（数十〜数百チャンク）なら **K=3〜5**。中規模なら **K=5〜10**。
- TopKを上げたら、必要なら閾値も少し上げてノイズを抑える（例：K=8 & 閾値=0.3）。

---
## 7. 発展：Rerankで「当たり」を上位に引き上げる
![Dif7.上級編：検索制度の限界を突破する「Rerank」](/images/Dify/Dif7.上級編：検索制度の限界を突破する「Rerank」.jpg)
### 図の要旨
- ハイブリッド検索（キーワード+ベクトル）で広く候補を集め、**Rerank**で“質問に最も効くチャンク”を再順位付けする方式です。
- 日本語はキーワード一致が効く場面（固有名詞/略語）が多いので、ハイブリッド+Rerankは効きやすいです。

### 詳細解説（用語）
- **ハイブリッド検索**：全文検索（BM25等）とベクトル検索を同時に使う。
- **Rerank**：候補チャンク集合を、別モデルで再スコアリングして順位を付け直す。
- **候補K（Stage1）/採用K（Stage2）**：まず多めに集め（例10件）、上位だけ採用（例3件）する。

### Tips（実務）
- Rerankは“精度ブースター”ですが、APIコストとレイテンシが増えます。まずはRerank無しで成立→最後に導入が安全。
- Rerank導入時は、Stage1のKを増やし（例：10〜20）、採用Kは3〜5に絞ると安定。

---
## 8. 失敗パターン⑤：検索結果がLLMに渡っていない（変数差し込みミス）
![Dif8.失敗パターン５：変数の「手入力」による切断](/images/Dify/Dif8.失敗パターン５：変数の「手入力」による切断.jpg)
### 図の要旨
- 知識検索が成功していても、LLMノードのSYSTEM/USERに **変数として挿入**していないと、LLMは検索結果を見ていません。
- “画面に見える文字列”を手入力しただけだと、Jinjaテンプレートが評価されず、ただの文字列扱いで失敗します。

### 詳細解説（用語）
- **変数挿入**：Difyの {x} ボタン等で、ノード出力（例：knowledge_search.result）をプロンプトに差し込む操作。
- **Jinja**：Difyが内部で使うテンプレート。<code v-pre>{{ ... }}</code> の形で変数を参照する。

### Tips（実務）
- 最短チェック：LLMノードの「最後の実行」で、SYSTEMに渡った最終プロンプト（render後）が“検索結果入り”かを確認。
- 知識検索ノードの出力変数名が `result` なのか `context` なのかは、ノード種別/バージョンで違うので、{x}から選択するのが安全。

---
## 9. 失敗パターン⑥：ハルシネーション（それっぽい嘘）
![Dif9.失敗パターン６：AIが「もっともらしい嘘」をつく](/images/Dify/Dif9.失敗パターン６：AIが「もっともらしい嘘」をつく.jpg)
### 図の要旨
- RAGでも、温度が高い/プロンプトが緩いと、LLMが“空白を想像で埋める”ことがあります。
- 対策は、(a) Temperatureを下げる、(b) コンテキスト優先を強制する、(c) 足りなければ「ナレッジに記載がありません」と返す、です。

### 詳細解説（用語）
- **Temperature**：出力のランダム性。低いほど決定的（同じ質問で同じ回答になりやすい）。
- **ハルシネーション**：根拠のない内容をもっともらしく生成すること。

### Tips（実務）
- RAGの目安：Temperature **0.2〜0.4**（安定と自然さのバランス）。
- “2段構え”（ナレッジ回答→一般論補足）をする場合も、**一般論は一般論として明示**し、ナレッジと混ぜない。

---
## 10. 失敗パターン⑦：回答が途中で切れる
![Dif10.失敗パターン７：回答が途中で途切れる](/images/Dify/Dif10.失敗パターン７：回答が途中で途切れる.jpg)
### 図の要旨
- 手順が長い/引用が多いと、出力トークン上限（Max tokens）に当たって途中で止まることがあります。
- この場合は（Max tokens）を上げるか、回答フォーマット（箇条書き/要約）を強制して短くします。

### 詳細解説（用語）
- **Max tokens**：LLMが出力できる最大トークン数。
- **トークン**：LLMの内部単位（日本語は文字数と1:1ではない）。

### Tips（実務）
- 目安：短いQAなら 256〜512、説明文なら 800〜1200、手順書なら 1500〜2500 もあり得る。
- まずは“要約→詳細”の2段（短文で出して続きはユーザーが要求）にすると、コストも抑えやすい。

---
## 11. 失敗パターン⑧：429（レート制限）で落ちる
![Dif11.失敗パターン８：ピーク時にシステムが停止する（429_Error）](/images/Dify/Dif11.失敗パターン８：ピーク時にシステムが停止する（429_Error）.jpg)
### 図の要旨
- アクセス集中や無料枠/制限で、モデルプロバイダが 429 を返すことがあります。
- 対策は、(a) APIキーを複数登録して分散、(b) リトライ+指数バックオフ、(c) 同時実行数を下げる、です。

### 詳細解説（用語）
- **429**：Too Many Requests。一定時間内のリクエスト数が上限を超えた。
  - FreePlanなどでよく遭遇、待ちたくない場合はLLMのモデルを変えるだけでも一時しのぎになる。（この制限はモデル単位であることが多い）  
- **バックオフ**：失敗時に待ち時間を徐々に増やすリトライ方式。

### Tips（実務）
- 障害対応では、まず“いつ/何回/どのノードで”429が出たかをログで把握する（p13）。
- Rerankを入れている場合、裏で追加コールが増えるので429が出やすくなる点に注意。

---
## 12. 失敗パターン⑨：コストが急増する
![Dif12.失敗パターン９：請求額の予期せぬ高騰](/images/Dify/Dif12.失敗パターン９：請求額の予期せぬ高騰.jpg)
### 図の要旨
- 原因の多くは、(a) TopK/チャンクが大きくてコンテキストが肥大化、(b) 高価なモデルを全ノードで使っている、(c) Rerank等で呼び出し回数が増えている、のいずれかです。
- ノードごとに“どれだけトークンを食ったか”を見て、コストの主因を特定します。

### 詳細解説（用語）
- **トークン課金**：入力トークン+出力トークンで課金されるモデルが多い。コンテキストが長いほど入力課金↑。

### Tips（実務）
- 原則：**検索（R）と生成（G）で役割分担**。生成は小〜中モデル（Flash等）で十分なことが多い。
- 評価質問セットで、コスト/正確性のトレードオフを見ながら段階的に。

---
## 13. デバッグの最短ルート：ログと変数検査
![Dif13.デブッグの極意：ログは「嘘」をつかない](/images/Dify/Dif13.デブッグの極意：ログは「嘘」をつかない.jpg)
### 図の要旨
- “ナレッジに記載がありません”が出た時は、(1)検索に当たっていない、(2)当たっているがLLMに渡っていない、(3)渡っているがプロンプトが壊れている、の3択です。
- このページは、どこを見れば切り分けできるか（変数・ログ）を示します。

### 詳細解説（用語）
- **変数検査**：各ノードの入出力（query/result/contextなど）を確認して、どこで欠落したかを見ること。

### Tips（実務）
- 知識検索ノード：`result` が空なら検索側。`result` が埋まっているならLLM側（変数差し込み or プロンプト）。
- LLMノード：SYSTEMのrender結果に検索結果が入っているか確認（8章）。

---
## 14. 症状→原因→調整弁のマトリクス
![Dif14.パラメータ調整マトリックス（TheTuningMatrix）](/images/Dify/Dif14.パラメータ調整マトリックス（TheTuningMatrix）.jpg)
### 図の要旨
- 現場で迷うのは“何から触るか”。このページは、症状ごとに優先して触る設定を整理した表です。
- 重要なのは **順番** で、まず **“入力→検索→連携→生成”** の順に疑うと遠回りしません。

### 詳細解説（用語）
- **調整順**：1つずつ変えるための“安全な順番”。

### Tips（実務）
- おすすめ順：①インデックス成功/ナレッジ選択 → ②変数差し込み → ③チャンク設計 → ④TopK → ⑤閾値 → ⑥Rerank → ⑦Temperature/Max tokens。

---
## 15. 本番化ロードマップ
![Dif15.プロダクションへの道（TheRoadToProduct）](/images/Dify/Dif15.プロダクションへの道（TheRoadToProduct）.jpg)
### 図の要旨
- 最後に、検証から本番運用へ移る時に必要な観点（監視/コスト/品質維持）が整理されています。
- PoCで終わらせず、運用できる形に落とすためのチェックリストと捉えると良いです。

### 詳細解説（用語）
- **本番化**：安定稼働（エラー率・遅延・コスト・品質）を一定水準で維持できる状態。

### Tips（実務）
- 運用では“設定値の履歴”が資産になります。変更ログ（いつ何をいじったか）を残す仕組みを用意する。
- ユーザーからのフィードバック（誤答例）を質問セットに追加し、回帰テストのように使う。



## 16. Dify RAG/LLM アプリ開発：精度を最大化する「調整弁（パラメータ）」関係図
![Dif16.Dify RAG/LLM アプリ開発：精度を最大化する「調整弁（パラメータ）」関係図](/images/Dify/Dif16.Dift_RAG&LLMアプリ開発：制度を最大化する「調整弁（パラメータ）」の関係図.jpg)

### 図の要旨（この1枚で何がわかるか）
- この図は、RAG を **検索フェーズ（Retriever）** と **生成フェーズ（Generator）** に分け、どのパラメータが「どこに効くか」を “配管図” として整理したものです。  
- 精度が出ない時に重要なのは、**①検索で当たりチャンクを取れているか** と **②その当たりを LLM に正しく渡せているか** をまず分離することです。  
- 調整は **1つだけ** 動かすのが鉄則です（複数同時に触ると原因が見えなくなります）。

<div class="video-container">
  <iframe
    src="https://drive.google.com/file/d/1dqlatyxplvP-wOcmn6KVleEo5v5ZmvUD/preview"
    allow="autoplay; encrypted-media"
    loading="lazy"
    style="width: 100%; aspect-ratio: 16 / 9; border: none; border-radius: 8px;"
  ></iframe>
</div>

---

## １）＜左側＞ 検索フェーズ：ナレッジから最適チャンクを取る
### A. チャンク設定とインデックス（検索の“土台”）
- **チャンク長（最大チャンク長）**
  - 小さすぎ：文脈が割れて「答えの片割れ」しか拾えない（Recall↓）
  - 大きすぎ：関係ない文が混ざりやすく、LLMが迷う（Precision↓）＋入力トークン増（コスト↑）
- **オーバーラップ**
  - 章境界・箇条書きの途中で情報が切れるのを防ぐ“保険”です。
- **埋め込みモデル（Embedding Model）**
  - 文章を意味ベクトルに変換するモデル。**これが変わるとベクトル空間が変わる**ため、通常は **再インデックス（再作成）** が必要です。  
  - 例：Embedding を `gemini-embedding-001` → 別モデルに変えた場合、古いベクトルは新モデルの検索と整合しない。

**推奨スタート（一般的な社内文書/手順書）**
- 最大チャンク長：**800〜1200 chars**
- オーバーラップ：**10〜25%（例：100〜200 chars）**
- インデックス方式：まずは **高品質**
- Embedding：一度決めたら当面固定（変更するなら“再インデックス前提”）

### B. リコール（呼び出し）強弱：セマンティクス vs キーワード（ハイブリッド時）
- **セマンティクス（意味）寄り**：言い換えに強い。概念・説明文・FAQに強い。
- **キーワード寄り**：固有名詞・型番・エラーコード・コマンドに強い。

**使い分け目安**
- 仕様/規程/概念説明：セマンティクス寄り（例：0.7〜1.0）
- 型番/製品名/エラー/ログ：キーワード寄り（例：0.4〜0.6）

### C. TopK とスコア閾値（検索結果の“量と質”）
- **TopK**
  - 役割：検索で返す **候補チャンク数（K件）**  
  - K↑ → **拾い漏れが減る（Recall↑）** が、**ノイズとコスト↑**
- **スコア閾値**
  - 役割：スコアが低い候補を捨てる **フィルタ**  
  - 閾値↑ → **ノイズ減（Precision↑）** が、**拾い漏れ増（Recall↓）**

**推奨スタート**
- TopK：小〜中規模なら **3〜5**
- スコア閾値：まず **0.0〜0.3**（緩め）  
  - ノイズが多い → 0.4〜0.6  
  - 法務/規程で厳密 → 0.6〜0.8 も検討（ただし “見つからない” が増えます）

---

## ２）＜右側＞ 生成フェーズ：コンテキストを元に回答を作る
### D. プロンプトとコンテキスト連携（最重要：ここで壊れやすい）
- 検索結果は、LLM に **変数として差し込まれて初めて** 参照されます。  
- Dify の設定で <code v-pre>{{#context#}}</code>  しか使えない場合は、SYSTEM（または USER）のプロンプト内に **必ず** <code v-pre>{{#context#}}</code>  を配置してください。  
  - 置き忘れると、検索が成功しても LLM は “何も見ていない” 状態になります。

**最短の切り分け**
1. 知識検索ノードの「最後の実行」で `result` が埋まっているか  
2. LLMノードの「最後の実行」で、最終プロンプト内に <code v-pre>{{#context#}}</code> の中身（検索結果）が入っているか

### E. 推論モデル（LLM）のパラメータ
- **Temperature（温度）**
  - 役割：出力のランダム性（創造性）  
  - 低いほど決定的（同じ質問に同じ答えが返りやすい）＝ハルシネーションが減りやすい
  - 目安：
    - RAG/業務QA：**0.2〜0.4**
    - ブレスト/文章生成：0.7〜1.0
- **Max Tokens（回答の長さ）**
  - 役割：途中で切れないようにする出力上限  
  - 目安：
    - 短いQA：256〜512
    - 仕様の説明：800〜1500
    - 手順書：1500〜2500

### F. Rerank（再順位付け）
- 役割：候補チャンク（TopKで集めたもの）を **別モデルで再評価** して、最適な順に並べ替える  
- 効果：Precision が上がりやすい（“当たり”が上に来る）  
- 代償：APIコール増（コスト↑・レイテンシ↑・429の当たりやすさ↑）

---

### ３） 実務で迷わない「調整の順番」（この順で触る）
1. **インデックスが成功しているか**（エラーなし／ステータス「利用可能」）  
2. **知識検索が当たっているか**（結果 `result` が埋まっているか）  
3. **LLMへコンテキストが渡っているか**（<code v-pre>{{#context#}}</code> の中身が入っているか）  
4. **チャンク設計**（長すぎ/短すぎ/オーバーラップ）  
5. **TopK**（拾い漏れ対策）  
6. **スコア閾値**（ノイズ対策）  
7. **（必要なら）Rerank / ハイブリッド重み**  
8. **Temperature / Max tokens**（ハルシネーション/途中切れ対策）

