# Kubernetes並列LLM評価：Docker化DeepEvalとJobマニフェストによる高速化戦略（ページ別解説）
---
## 1. 全体像：K8sでLLM評価を“生産ライン化”する
![Dk1.Kuvernetes並列LLM評価：Docker化DeepEvalとJobマニュフェストによる高速化戦略](/images/IaC/Dk1.Kuvernetes並列LLM評価：Docker化DeepEvalとJobマニュフェストによる高速化戦略.jpg)

### 図の要旨
- **Docker化したDeepEvalコンテナ**を、Kubernetes上で大量に起動し、評価（テスト）を並列実行して“高速化”する全体像です。
- 左の入力（プロンプト/評価データ）→ 中央のオーケストレーション（Kubernetes）→ 右の並列処理（コンテナ群）→ 出力（集約結果/メトリクスDB）の流れを表しています。
- “評価を回せない＝品質が落ちる/デプロイできない”問題を、インフラで解決する発想です。

### 詳細解説（用語）
- **LLM評価（Evaluation）**：LLMアプリの応答を、正しさ/根拠整合/関連性などの観点で点数化・合否判定すること。
- **DeepEval**：LLM向けの評価フレームワーク（pytestライクにテストケースを書き、メトリクスで判定）。
- **オーケストレーション**：多数の処理を、起動・分散・監視・終了まで“まとめて制御”すること。

### Tips（実務）
- まずは **「小セット（20ケース）」を毎PR**、**「大セット（500〜5,000）」を夜間**に分けると、速度と品質が両立します。
- “並列化”は万能ではないので、最初に **1ケースあたりの平均時間（と95%ile）** を測ると、必要Pod数の見積りができます。

---
## 2. 課題：LLM評価における「時間の壁」とスケーラビリティ
![Dk2.課題：LLM評価における「時間の壁」とスケーラビリティ](/images/IaC/Dk2.課題：LLM評価における「時間の壁」とスケーラビリティ.jpg)
### 図の要旨
- ローカル/単一プロセスの逐次実行（Serial）だと、ケース数が増えるほど評価時間が直線的に伸びます（例：**5,000テスト＝24時間**）。
- K8sで並列化すると、目標として **“20分”** に短縮できる（DevOpsサイクルを止めない）ことを示しています。
- 評価が追いつかないと、古い指標のままリリースされ、品質事故（ハルシネーション等）を抱えたまま本番へ行くリスクが増えます。

### 詳細解説（用語）
- **スケーラビリティ**：負荷（テストケース数）が増えても、リソース追加で処理時間を抑えられる性質。
- **DevOpsサイクル**：変更→テスト→デプロイ→監視→改善の反復。評価が遅いとサイクルが止まります。
- **ハルシネーション**：根拠のない内容を“それっぽく”生成する現象（評価で検知したい代表例）。

### Tips（実務）
- 並列化の上限は、CPU/GPUだけでなく **外部LLMのレート制限（429）** や **ネットワーク帯域** でも決まります。
- いきなり“最大並列”にしないで、**parallelismを小さく→測定→段階的に増やす**のが事故りにくいです。

---
## 3. ソリューション全体：3つの技術要素（DeepEval × Docker × Kubernetes）
![Dk3.ソリューションアーキテクチャ概要：３つの技術要素](/images/IaC/Dk3.ソリューションアーキテクチャ概要：３つの技術要素.jpg)
### 図の要旨
- 解決策は3層構造：
  1) **評価ロジック（DeepEval）**：何をどう採点するか
  2) **実行環境（Docker）**：依存関係を固定し再現性を担保
  3) **並列実行（Kubernetes）**：Jobコントローラで大量Podを展開
- 目的は「アプリ内のテスト」から「**インフラベースのテスト**」へ移行することです。

### 詳細解説（用語）
- **再現性（Reproducibility）**：同じコード・同じ条件なら同じ結果になる性質。評価では最重要です。
- **依存関係（Dependencies）**：Python/ライブラリ/OS/ドライバ等。ズレると結果が変わる・動かない原因になります。
- **Kubernetes Job**：完了したら終了する“一回きりのバッチ処理”向けリソース（評価と相性が良い）。

### Tips（実務）
- 3層を一気に作らず、まず **DeepEvalでテストが書ける** → 次に **Dockerで動く** → 最後に **K8sで増やす** の順が最短です。
- “評価の定義（メトリクスと閾値）”は、運用しながら育てる前提でOKです（後で調整できるようログ/結果を残す）。

---
## 4. 評価ロジック：DeepEvalフレームワーク（pytest的にLLMを単体テストする）
![Dk4.評価ロジック：DeepEvalフレームワークの採用](/images/IaC/Dk4.評価ロジック：DeepEvalフレームワークの採用.jpg)
### 図の要旨
- DeepEvalは **pytestと統合**でき、LLMの応答を“テストケース”として記述し、メトリクスで採点します。
- 主要メトリクス例：
  - **Answer Relevancy（回答関連性）**
  - **Faithfulness / Hallucination（根拠整合・ハルシネーション検知）**
  - **G-Eval（LLM-as-a-Judge）**

### 詳細解説（用語）
- **テストケース**：入力（質問/指示）と、実際の出力（LLM回答）をセットにした最小単位。
- **Answer Relevancy**：質問に対して“的外れでないか”を評価する指標。
- **Faithfulness**：RAG等で与えた根拠（コンテキスト）に忠実か（根拠に無い断定をしていないか）。
- **G-Eval**：別のLLMを“採点者”として使い、ルーブリックに基づいて評価する方式（高精度だがコスト/レイテンシ増）。

### Tips（実務）
- 最初は **Relevancy + Faithfulness** の2本で回し、必要になってからG-Evalを追加すると運用負荷が低いです。
- テストケースは「失敗した実例（誤答/事故）を追加し続ける」と、品質が積み上がります（回帰テスト資産）。

---
## 5. 実行環境のDocker化：依存固定と軽量化、Cold Start対策
![Dk5.実行環境のDocker化：再現性の担保](/images/IaC/Dk5.実行環境のDocker化：再現性の担保.jpg)
### 図の要旨
- 評価環境は **Dockerで固定**し、「ローカルでは動くがCIでは動かない」問題を排除します。
- 依存関係（Python、PyTorch/CUDA、DeepEval等）を封じ込め、評価結果の再現性を確保します。
- **Multi-stage build**でイメージを軽量化し、モデル重み（Weights）は **イメージに入れずマウント**してCold Startを抑える方針です。

### 詳細解説（用語）
- **依存のピン止め（Pinning）**：`package==version` のように固定し、評価結果が日によって変わる事故を防ぎます。
- **Multi-stage build**：ビルド工程と実行工程を分け、最終イメージを小さく・速くするDockerの手法。
- **Weights（モデル重み）**：LLM/埋め込みモデル等の巨大ファイル。毎回DLすると起動が遅くなります。
- **Cold Start**：Pod起動時のダウンロード/初期化で時間がかかる現象。

### Tips（実務）
- 評価は短命Podなので、基本は **起動時間の最適化** が効きます（イメージサイズ削減＋キャッシュ利用）。
- HuggingFace系ならキャッシュ（例：`~/.cache/huggingface`）を永続化するだけで、2回目以降が大幅に速くなります。

---
## 6. 核心戦略：Kubernetes Jobで“バッチ並列実行”（Deploymentではない）
![Dk6.核心戦略：KubernetesJobによる並列実行](/images/IaC/Dk6.核心戦略：KubernetesJobによる並列実行.jpg)
### 図の要旨
- 評価プロセスは常駐サービスではなく **「完了のあるタスク」** なので、K8sの **Job** が適切です。
- Jobコントローラが複数Podを起動し、各Podがデータセットの一部を処理して終わります。
- “1台が1,000タスク”ではなく、“100Podが10タスクずつ”の発想で時間短縮します。

### 詳細解説（用語）
- **Deployment**：常時稼働させるサービス（Web/API）向け。落ちたら復旧して継続稼働が目的。
- **Job**：完了したら終了するバッチ向け。成功/失敗の回数を管理します。
- **Pod**：K8sの最小実行単位（コンテナのまとまり）。

### Tips（実務）
- 評価が“常時”必要ならJobをスケジュールする（CronJob/Argo）形にし、サービスとして作らないほうがシンプルです。
- Jobはログが分散するので、Pod名・インデックス・run_id などをログに埋めると調査が速いです。

---
## 7. Jobマニフェスト：並列数（parallelism）と完了数（completions）
![Dk7.Jobマニュフェストの定義：並列数と完了数](/images/IaC/Dk7.Jobマニュフェストの定義：並列数と完了数.jpg)
### 図の要旨
- マニフェストで“どれだけ分割して、同時に何個動かすか”を決めます。
- 図では主要パラメータ：
  1) **completions**：実行すべき全タスク（テストケース）の総数（または分割数）
  2) **parallelism**：同時に立ち上げるPod数の最大
  3) **image**：評価用Dockerイメージ
- GPUを使う場合は `resources` で `nvidia.com/gpu` を指定します。

### 詳細解説（用語）
- **completions**：Jobが“完了”とみなす回数。Indexed Jobの分割数に使います。
- **parallelism**：同時実行の上限。上げすぎるとGPU/外部LLM/帯域で詰まります。
- **resources.requests/limits**：CPU/メモリ/GPUの要求量と上限。スケジューリングに影響します。

### Tips（実務）
- 初期値は小さめ（例：`parallelism: 2〜5`）で測定→段階的に上げるのが安全です。
- 外部LLMをJudgeに使うなら、`parallelism` は **レート制限** に引っ張られることが多いです（429が出たら下げる）。

---
## 8. Indexed Jobによるデータシャーディング（JOB_COMPLETION_INDEX）
![Dk8.IndexedJobによるデータシャーディング](/images/IaC/Dk8.IndexedJobによるデータシャーディング.jpg)
### 図の要旨
- K8sが各Podにユニークなインデックス番号（環境変数 `JOB_COMPLETION_INDEX`）を自動付与します。
- スクリプト側はこの番号を読み取り、データセット全体から自分の担当分（シャード）だけを処理します。
- これにより **重複実行を防ぎ**、静的に分割して並列処理できます。

### 詳細解説（用語）
- **Indexed Job**：`completionMode: Indexed` を使うJob。Podに 0..N-1 の番号が付くため、担当分割が簡単になります。
- **Sharding（シャーディング）**：データを分割して並列処理すること。
- **Data Slice**：担当範囲の切り出し（例：0〜333、334〜666…）。

### Tips（実務）
- スクリプト設計は `--shard-index N --total-shards M` の形にすると、ローカルでも同じ方法で再現できます。
- ケースの“重さ”が偏る場合は、単純な連番スライスでは待ちが出ます。まずは静的で始め、偏りが大きいならキュー方式を検討です。

---
## 9. GPU最適化：Time-Slicing / MIG（1枚のGPUを分割して使う）
![Dk9.GPUリソースの最適化：Time-Slicing戦略](/images/IaC/Dk9.GPUリソースの最適化：Time-Slicing戦略.jpg)
### 図の要旨
- G-Eval等でGPUが必要になる場合、1枚のGPUを複数Podで共有し、限られたGPUで並列度（parallelism）を稼ぐ戦略です。
- **Time-Slicing** は“時間で共有”する方式で、複数Podが同じ物理GPUを順番に使うイメージです。
- 併記されている **MIG** は“ハード分割”で、より隔離・安定性が高い方式です（対応GPUが必要）。

### 詳細解説（用語）
- **Time-Slicing**：GPUを時間スロットで共有。導入しやすい一方、負荷でレイテンシがぶれやすい。
- **MIG（Multi-Instance GPU）**：GPUを複数の“仮想GPU”に分割し、リソースを隔離。安定しやすい。
- **スループット**：一定時間あたりに処理できるテスト数。GPU共有で上げたい指標です。

### Tips（実務）
- まずはGPU分割より先に **`parallelism` を控えめにして安定運用** → その後にTime-Slicing/MIGで密度を上げる順が安全です。
- CPU環境でも、この章は“将来GPUを入れる時の設計メモ”として残しておくと、必要になった瞬間に効きます。

---
## 10. 評価結果の集約と永続化：分散JSONを1つのレポートへ
![Dk10.評価結果の集約と永続化](/images/IaC/Dk10.評価結果の集約と永続化.jpg)
### 図の要旨
- 各Podは独立して動くため、結果は分散（断片化）します。
- 共有ストレージ（**Shared PVC**）や **S3 Bucket** にJSONとして書き出し、最後に **Aggregator Pod** がマージして単一レポートを作ります。
- その後、ダッシュボードに表示したり、CIの合否判定に使います。

### 詳細解説（用語）
- **PVC（PersistentVolumeClaim）**：Podから使える永続ボリュームの要求。結果/キャッシュの保存に使います。
- **オブジェクトストレージ（S3等）**：ファイル（JSON）を置くのに強いストレージ。短命Podと相性が良いです。
- **集約（Aggregation）**：シャードごとの結果をマージし、全体メトリクス（平均/分布/合否）を計算する工程。

### Tips（実務）
- 最初は **S3等にJSONを置く** 方が運用がラクなことが多いです（RWXのPVCが用意できないクラスタもあるため）。
- JSONには `run_id / commit_sha / shard_index` を必ず入れ、後から“この結果はどのコード？”が追えるようにします。

---
## 11. ワークフロー自動化：CI/CD統合とQuality Gate（合否でマージを止める）
![Dk11.ワークフローの自働化：ＣＩＣＤへの統合](/images/IaC/Dk11.ワークフローの自働化：ＣＩＣＤへの統合.jpg)
### 図の要旨
- Code Commit/PR → Docker Build → K8s Job起動 → 結果集約 → **Quality Gate（合否）** の一直線パイプラインです。
- Argo Workflows / GitHub Actions 等で自動化し、評価スコアが基準を下回るとマージ/デプロイをブロックします。

### 詳細解説（用語）
- **Quality Gate**：メトリクス閾値を満たさない場合に、次工程（マージ/デプロイ）へ進ませない仕組み。
- **CI/CD**：継続的インテグレーション/デリバリ。テストとデプロイを自動化する考え方。
- **PR（Pull Request）**：変更提案。ここで評価を回すと“壊したまま本番へ”を防げます。

### Tips（実務）
- Gateは最初から厳しくしすぎない：まずは“警告（通知）”運用→安定したら“ブロック”へ移行が現実的です。
- PRコメントに「合否」「主要メトリクス」「悪化ケースTOP10」を返すと、レビューが爆速になります。

---
## 12. 全体構成図：DeepEval on K8s Architecture（実データフロー）
![Dk12.全体構成図：DeepEvalOnK8sArchitechture](/images/IaC/Dk12.全体構成図：DeepEvalOnK8sArchitechture.jpg)
### 図の要旨
- 開発者がコードをPush → CIがDockerイメージをビルドしてレジストリへPush。
- K8sクラスタがイメージをPullしてJobを起動し、複数Pod（Indexed 0..N）が評価を実行。
- 各Podは共有GPU（Time-Slicing）を使いつつJSONを書き出し、Aggregatorが読み込んで最終レポート化します。

### 詳細解説（用語）
- **Container Registry**：Dockerイメージの保管場所（ECR/GHCR等）。
- **Job Controller**：Jobを監視し、必要なPodを起動/管理するK8sコンポーネント。
- **Shared Volume**：複数Podからアクセスする共有ストレージ（結果/キャッシュ）。

### Tips（実務）
- 最初は“図の全部”を作らなくてOKです。最短は **K8s Job → S3へJSON → ローカルで集約** でも成立します。
- 本番運用では、監視対象は「Pod失敗率」「実行時間」「GPU利用率」「外部API 429」です。

---
## 13. 導入効果とROI：SPEED / VELOCITY / RELIABILITY
![Dk13.導入効果とROI](/images/IaC/Dk13.導入効果とROI.jpg)
### 図の要旨
- **SPEED**：24時間→20分（評価時間の劇的短縮）
- **VELOCITY**：Dev Loopを高速化し、1日に複数回の改善サイクルが回る
- **RELIABILITY**：Docker + K8sで環境差異を排除し、再現性を確保

### 詳細解説（用語）
- **Dev Loop**：実装→テスト→修正の短い反復。短いほど改善が速いです。
- **環境差異**：OS/ライブラリ/ドライバなどの違いで挙動が変わる問題。評価では致命的。
- **再現性**：同じ条件なら同じ評価結果が得られること（比較・改善に必須）。

### Tips（実務）
- 価値が出るのは“継続”です。評価をCIに入れ、失敗ケースを追加し続けると品質が積み上がります。
- ROIを見せるなら、**評価時間（分）・コスト（¥）・品質メトリクス（スコア）** を毎週トレンドで残すのが有効です。

---
## 14. 実装への3ステップ：小さく始めて、大きく育てる
![Dk14.実装への３ステップ](/images/IaC/Dk14.実装への３ステップ.jpg)
### 図の要旨
- 1) **Docker化（Containerize）**：依存を含めたDockerfileを作る（重みはマウント）
- 2) **マニフェスト定義（Define Manifest）**：Job/Indexed/parallelismでデータ分割ロジックを実装
- 3) **パイプライン統合（Integrate Pipeline）**：CIからK8s Jobをキックし、集約して可視化
- 結論：**ローカルDockerで小さく始め、K8s並列でスケール**

### 詳細解説（用語）
- **マニフェスト（YAML）**：K8sの設定ファイル。Jobの並列度やイメージを定義します。
- **データ分割ロジック**：`JOB_COMPLETION_INDEX` を使って担当範囲を決めるコード。
- **可視化（Visualization）**：結果をダッシュボード/レポートにして、改善点を見える化します。

### Tips（実務）
- 実務の“最短”は：Dockerize → Indexed Job → S3集約 の3点セットです。ArgoやGPU分割は後からでもOK。
- 「どこで詰まるか」を先に決める：CPU/GPU/外部LLM/ストレージのどれがボトルネックかを測ってから最適化すると迷いません。

---
## 15. 参考資料とNext Steps：公式ドキュメントで深掘りする
![Dk15.参考資料：NextSteps](/images/IaC/Dk15.参考資料：NextSteps.jpg)
### 図の要旨
- 次に読むべき一次情報として、
  - DeepEvalのメトリクス/カスタマイズ
  - Kubernetes Jobs（Indexed Job/Parallel Processing）
  - NVIDIA GPU Operator（Time-Slicing）
 へのリンクが整理されています。
- “評価のボトルネックを潰して、信頼できるAIアプリを最速でデリバリーする”というメッセージで締めています。

### 詳細解説（用語）
- **一次情報（Primary Source）**：公式ドキュメント。運用フェーズで最も頼れる情報源です。
- **GPU Operator**：K8sでGPUを扱うための拡張コンポーネント群（プラグイン/ドライバ管理など）。

### Tips（実務）
- 運用で困ったら、まずは **「レート制限」「Pod配置」「ストレージモード（RWX）」「GPUプラグイン」** の4点を疑うと切り分けが速いです。
- 公式ドキュメントは“設計の根拠”にもなるので、社内説明資料ではリンクを残しておくと後から効きます。
