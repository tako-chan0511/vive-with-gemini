# 現場で磨かれるAI活用術：Vive-with-Gemini実践編（概要）

前回のコラムでは、AIと共に動くチームの中で自然に生まれた  
“会話駆動型アジャイル”の姿を紹介しました。  
今回はそこから一歩踏み込み、現場レベルでAIをどう活用しているのか、  
そのエッセンスを紹介します。  

（※内部設計指針や具体的なコード規約の詳細は守秘義務もありすべては展開できませんが、  
雰囲気を感じ取っていただければ幸いです）

---

## 💡 AI活用の基本スタンス

AIを「自動化の道具」としてではなく、  
**共に考える相棒**として扱うことが出発点です。  
AIはチームの一員として設計・実装・テストすべての工程に関わり、  
人は常に “意図” と “品質” を確認する立場に立ちます。

同時に、私たちが土台に置いているのは、  

> **チームの価値は「単位時間あたりに得られるフィードバック量」にほぼ比例する**

という考え方です。

- 仕様・要件レベルのフィードバック（＝お客様・業務側からの声）  
- 設計・レビューでのフィードバック（＝矛盾・抜け漏れ・複雑さの発見）  
- 実装・テストでのフィードバック（＝テスト結果・ログ・監視）

これらの**価値提供ループ（フィードバックループ）を、いかに短いサイクルで何度も回せるか**が、  
そのまま ROI（価値 ÷ コスト）に効いてくると捉えています。

そこで現在のプロジェクトでは、次のようなかたちで  
「AI＋自働化」によるループ短縮を図っています。

- **設計フェーズ**  
  - API定義書（OpenAPI）やDB設計、社内規約をAIに読み込ませ、  
    設計レビュー案・ユースケース洗い出し・例外パターンのチェックを半自動化。  
  - 仕様変更があったときも、AIに「差分」と「影響箇所」を洗い出させ、  
    レビューにかかる時間と認識ズレを圧縮。

- **実装フェーズ**  
  - 既存の良い実装パターンをプロンプトに埋め込み、  
    Lambda／ストアドファンクション／DTO などのひな形をAIに生成させることで、  
    “ゼロから書く時間” を削減。  
  - 開発者はビジネスロジックや例外ケースの詰めに集中できるようにしている。

- **テストフェーズ**  
  - pytest＋parametrize＋共通関数というプロジェクト標準を前提に、  
    「この関数をC1条件網羅でテストして」とAIに依頼してテスト雛形を生成。  
  - 差分修正が入ったときも、AIに「ここにテストを足すべき」「このケースが抜けている」と  
    指摘させることで、リグレッション検討の時間を短縮。

- **CI/CD・自働化**  
  - 将来的には、上記でAIが支援した設計・実装・テストの成果物を  
    CI/CDパイプライン（lint／ユニットテスト／結合テスト／デプロイ）にそのまま流し込み、  
    **「コードを書いたらすぐパイプラインが動き、結果が返ってくる」ループ** を強化していく構想です。  
  - これにより、「人が確認しに行く」時間を減らし、  
    ツール側から自動的にフィードバックが届く状態を目指しています。

その前提として意識しているのが、**AIは確率の世界で「もっともらしい答え」を返す存在**だという点です。  
下図のように、**どれくらい広く答えを許すか（自由度＝ばらつき）**を変えることで、  
こちらが期待する役割も変わってきます。

- 左のようにばらつき（σ）が大きい状態：  
  → 発想を広げたいとき（アイデア出し・バリエーション出しなど）に向いている。  
- 右のようにばらつき（σ）が小さい状態：  
  → 品質や生産性をしっかり高めたいときに向いている。

![AIは確率の世界で判断](./public/images/vive/AIは確率の世界で判断.jpg)

そのため、AIを活用するときは

- **アイデア拡散モード**（左図：自由度高め・抽象度高め）  
- **品質・生産性向上モード**（右図：枠組みをはっきり決めて自由度を絞る）

の2つを意識して使い分けます。  

特に後者では、抽象的な指示よりも、アーキテクチャ設計やフレームワーク、命名規則など  
**“枠組みが明確な領域”をきちんと用意し、その中で動いてもらう**ほうが安定します。  

ここでいう「枠組み」は、私たちの現場では大きく **ローカル規約** と **グローバル規約** の二層構造になっています。  
プロジェクト固有の設計・コーディング・テスト規約と、世界共通のベストプラクティスの両方をAIに渡すことで、  
**「ブレない設計・実装」を維持しつつ、高速なフィードバックループを回す** ことを狙っています。  

結果として、AIを「自由にさせすぎない」ことが、  

- 各フェーズのリードタイム短縮（設計・実装・テスト・レビュー）  
- CI/CDによる自働化と組み合わせたフィードバックループの高速化  

につながり、**品質と生産性を同時に引き上げるための重要なポイント**になっていると感じています。

---

## 🔧 ローカル規約 × グローバル規約 × AI

![AI成果物](./public/images/vive/AI成果物.jpg)

先ほど触れた「枠組み」を、もう少し具体的に分解したのがこの図です。  
私たちの現場では、AIに「ゼロから全部考えさせる」のではなく、  
上の図のように **ローカル規約とグローバル規約を両側から与えたうえで、成果物を一緒に作る** 形をとっています。

---

## 🧭 開発現場でのAI活用ポイント（概要）

ここで挙げる「設計」「実装」「テスト」「チェック」は、  
いわゆるウォーターフォールの工程表ではありません。  

私たちは、**価値提供のためのフィードバックループ**をどう短く・濃く回すか、  
そのループを **AIと一緒に逐次チューニングしている** というイメージで捉えています。

- 「仕様通りに作ったから自分は悪くない」  
- 「要件が曖昧だったから失敗した」  

と誰かのせいにするのではなく、  
**チームとしてどれだけ価値を届けられたか** を基準に考え、  
POが個人を責めたり、メンバーがPOを責めたりしないように意識しています。  

まだまだ志半ばですが、  
「どうすれば価値提供が良くなるか？」を起点に、  
自己組織化していくチームを目指して、以下のループを回しています。

---

### 1️⃣ 設計フェーズ：AIによる規範理解と設計レビュー

設計の目的は「仕様通りに作る証拠を残すこと」ではなく、  
**後続の実装・テスト・運用が迷わないだけの“よい土台”をつくること** だと考えています。

そのために、社内標準やコーディング規約、API定義書（OpenAPI）、DB設計方針などを  
AIに読み込ませ、設計段階からの品質チェックを半自動化しています。

- 命名規則・データ構造・例外処理パターンの逸脱をAIが検出  
- API仕様とデータ設計の整合性をAIが補助的に検証  
- 仕様差分が出たときに、影響箇所の洗い出しをAIに手伝わせる  

また、**公的なアーキテクチャパターンやデザイン原則の上に小さな部品を積み上げる**  
“コンポーネント指向”のアプローチを採用しています。  

AIはこうした一般論・標準パターンといった「教科書的な土台」には特に強く、  
そこにプロジェクト固有の制約やデータ（API定義書、DB設計、命名規約など）を食べさせることで、  
**このプロジェクトならではの差別化された解** を返してくれるようになります。

結果として、AIはこの土台を理解したうえでピンポイントな改善提案を行い、  
**全体構造を壊さずに部分最適を進める** ことを助けてくれます。  
ここで得られた気づきは、すぐに次のスプリントの改善テーマとして  
POもメンバーも一緒に持ち帰るようにしています。

---

### 2️⃣ 実装フェーズ：パターン化された知識の活用

実装の場では、「仕様通りに書けているか」を責め合うのではなく、  
**チームとしてどれだけ安全・速く価値を届けられるか** にフォーカスしています。

実際のプロジェクトで蓄積した良質なコードパターンをAIに共有し、  
設計情報（API定義書、テーブル設計、処理フロー）を入力すると初期コードを自動生成。  

- Lambda／ストアドファンクション／DTOなどの雛形をAIに生成させる  
- 人は意図・例外ケース・業務ロジックの詰めに集中  
- 開発者同士の議論も、AIを交えた設計対話として発展  

こうした仕組みは、**堅牢なアーキテクチャとAI支援の融合**によってこそ機能します。  
現在のプロジェクトでも、API Gateway＋Lambda パターンを中核とし、  
データアクセス層はストアドファンクションで統制。  

明確な責務分離の上でAIを活用することで、  
**生成結果の整合性・安全性・再利用性** が格段に高まっています。  

「誰が書いたか」ではなく、「このパターンなら将来のメンテが楽か？」という観点で  
PO・メンバーが同じ方向を向きやすくなっているのも、AI導入後の変化です。

---

### 3️⃣ テストフェーズ：AIによる自動生成と自己追随

テストでは、「テストを書いた／書いていない」で個人を責めるのではなく、  
**チームとしてどこまでリスクを可視化できているか** を重視しています。

実装コードをAIに解析させ、  
指示（例：「C1条件網羅で」「外部APIはMock環境で」）を与えるだけでテストコードを生成。  
修正後もAIが差分を理解し、テストの追加・修正ポイントを提案させています。

このように、AI生成と人間設計のハイブリッドにより、

- 「1関数＝1テスト単位」  
- 「parametrizeによる多様ケース対応」  
- 「共通関数による標準化」

という **三層構造のテスト設計** を確立しつつあります。

テスト資産はセーフティネットとして“生きたまま”維持され、  
品質保証とアジャイル性を両立したテスト基盤の上で、  
安心してリファクタリングや仕様変更に踏み込めるようになってきました。  

今後は、このテスト基盤をそのまま土台として、  
**CI/CDパイプライン上での自動テスト実行～自動デプロイ** までを一気通貫でつなぎ、  
AIが絡んだインクリメンタル開発を、より高速なフィードバックループとして回していく構想です。

---

### 4️⃣ チェックフェーズ：人による最終確認（他責化から抜けるための仕組み）

すべてのコード・テストはAIチェックを経たうえで、  
最終判断はあくまで人が行います。  

- AIが形式面・整合性・抜け漏れの指摘を担当  
- 人が「この機能は本当に価値があるか？」「業務の意図に合っているか？」を判断  

という役割分担を意識することで、  
**「誰のせいでこうなったか」を探すチェック** から、  
**「次にどう良くするか」を一緒に考えるチェック** へと軸足を移しています。

ウォーターフォール型の進め方だと、

- 「仕様通りに作ったから自分は悪くない」  
- 「要件が曖昧だったから失敗した」  

といった **他責化** がどうしても起きがちです。  

私たちは、AIによる客観的なチェックとプロセスの見える化をうまく使うことで、  
**個人を責める材料ではなく、チームの改善材料として事実を扱う** ことを意識しています。

AIによるチェックと人のレビュー、そしてスプリントレビューでの対話を組み合わせることで、  
**品質・価値・学び** の三つを同時に高めていくことを目指しています。

＜補足＞スクラムのスプリントレビューについて、  
よくある誤解は「承認ゲート」だと思われがちな点です。  
本来は「動くもの」をステークホルダーに見せ、  
そこで得られるフィードバックや追加要望などを収集する場です。  

私たちも、**POがメンバーを責める場にしない／メンバーがPOを責める場にしない** ことを共通認識とし、  
「ここから何を学んで次スプリントをどう良くするか？」という視点で話すようにしています。  

そこで得た気づきが、AIを活用したインクリメンタルな改善サイクルにつながる  
**重要な情報源**となります。

さらに、この「他責化しないチェック」とAIを前提にした見える化が、  
少しずつ **心理的安全性** にも効いてきていると感じます。  

最近の朝会では、メンバーから

> 「今日のタスクはここまでで終わりそうなので、  
>  次はこのチケットを触ってもいいですか？」

といった前向きな相談が頻繁に出るようになりました。  

「指示を待つ」のではなく、  
**自分からバックログを見に行き、チームとしての価値提供をどう前に進めるかを一緒に考える**  
という振る舞いが増えてきたのは、  
まさに心理的安全性が少しずつ高まり、  
チームがアジャイルな方向へ自己組織化し始めているサインだと受け止めています。

---

## 🌪 ＜補足説明＞フィードバック量とROI最大化のイメージ

![フィードバックループ](./public/images/vive/フィードバックループ.png)

上の図は、アジャイル開発を **同心円状のフィードバックループ** として表現したものです。

- 外側：**Strategy / Release**  
- 中側：**Iteration / Sprint**  
- さらに内側：**Daily / Continuous**（TDD・ビルド・リファクタリングなど）  
- すべてのループの矢印が、右下の **Working Software（動くソフトウェア）** に向かっている

まわりには「Values」「Visibility」と書かれていて、  

- 価値観（adaptability, transparency, simplicity ...）  
- 見える化（velocity, burndown, tests ...）  

が、このループを支えていることを示しています。

ここで私たちが大事にしているのは、

> **チームの価値は、「単位時間あたりに得られるフィードバック量」にほぼ比例する**

という考え方です。

- Strategy／Release レベルの大きなフィードバック  
- Sprint／Daily の中くらいのフィードバック  
- TDD／自動テスト／監視ログなどの細かいフィードバック  

これらを **絶えず（-ing）回し続ける** ことで、  
「今やっていることは本当に価値につながっているか？」を  
常に確認しながら進められます。

Vive-with-Gemini の取り組みでは、このフィードバックループの各レイヤーに  
AIを組み込み、**フィードバックの頻度と質を同時に高める** ことを狙っています。

- 上位レベルでは：要件・仕様のすり合わせをAIと一緒に整理し、  
  誤解や抜け漏れを早い段階で潰す。  
- 実装レベルでは：設計レビューやテスト生成をAIに支援させ、  
  一つひとつの変更に対する安全網を厚くする。  

こうして、

> **ROI = 価値 ÷ コスト**

の観点で見たときに、  

- 「価値」側は、フィードバックの密度を高めてプロダクトの方向性を磨き込み、  
- 「コスト」側は、AIによる自動化と標準化で無駄な手戻りを減らす、  

という二正面からのアプローチで、  
**ROI最大化を常に意識したアジャイルな開発サイクル** を回している、  
というのがこの図で伝えたいメッセージです。

---

## ⚙️ 成果と変化

まだ“我流アジャイル”の段階ではありますが、  
チームの中に **「少しでも良くするために今日できることは何か？」** を考える習慣が  
確実に根づきつつあると感じています。

- チームメンバーが **AIとの会話を軸に作業を進める** ようになり、  
  「とりあえず聞いてみる・試してみる」小さなサイクルが当たり前になってきた。  
- コミュニケーションの質が上がり、  
  会議・チャット・設計議論すべてが **思考の共有と学び合いの場** に近づいてきた。  
- その積み重ねの結果として、プロセスは少しずつ自然にアジャイル寄りになり、  
  完成形ではないものの、**自主性とスピードを両立しようとする動き** が見え始めている。  

![アジャイルに変えてからのVelocityの変化](./public/images/vive/アジャイルに変えてからのVelocityの変化.png)

また結果の一つとして、上図のような **バーンダウンチャート** にも変化が現れました。  
アジャイルに切り替えたタイミング（青矢印付近）を境に、実績線が徐々に理想線へ近づき、  
**Velocity のブレが小さくなり、完了までの見通しも立てやすくなってきた** ことが分かります。  
「どのくらいのペースで価値を届けられているか」が数字として見えるようになったことで、  
次のスプリント計画や、改善ポイントの議論もしやすくなりました。

さらに印象的だったのは、AIが提示する設計思想やコード提案には、  
時に誤りや矛盾が含まれるにもかかわらず、  
**その“半信半疑の対話”こそが自分の理解を深めるきっかけ** になっていることです。  

AIの出力を鵜呑みにせず、「なぜそうなるのか？」を自分の言葉で咀嚼して取り込む過程が、  
結果的に知識の定着と拡張を生み出しました。  

言い換えれば、**AIの“間違い”も学習資源として活かしながら、  
アジャイルなあり方を学び続けているチームになりつつある** ことが、  
このプロジェクト最大の成果の一つだと感じています。

---

## 💬 結び

**チームがAIを通してアジャイルに成長していく──  
それが Vive-with-Gemini の実践です。**

---

## 🔗 Tips集（補足詳細説明など）

👉 [「AI技術の変遷による変化：2015年-vs-2025年」](./ai-agile-vive-with-gemini-column-2015-vs-2025)
1. 2015年の常識：「相関関係の計算機」
2. 2017年の革命と「NVIDIA一強」の理由
3. 量が質を変えた：「創発」という現象
4. 現場での活用技術：RAGとLoRA
5. そして未来へ：「学習」から「推論」の時代
結論：Vive-with-Gemini が「相棒」と呼ぶ理由
